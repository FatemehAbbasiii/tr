{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdFKXUgYClai"
      },
      "source": [
        "# Add & install Important Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EydbvO8MCjnL",
        "outputId": "34f8d479-9050-4fdc-ccec-b0ebf5fd9f40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.0-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Collecting responses<0.19 (from datasets)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.20.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.30.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=5044a78cf85984b11be2bd2d0a2965faaa344abeaa688c48e248440dabe9ea5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-2.2.2 sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install --upgrade accelerate\n",
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGDQn0LTCzaW",
        "outputId": "0c498ead-94ff-4386-83bb-9ea94c961296"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fairseq\n",
            "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.15.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq) (0.29.34)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq) (2022.10.31)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq)\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq) (4.65.0)\n",
            "Collecting bitarray (from fairseq)\n",
            "  Downloading bitarray-2.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (273 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.7/273.7 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.0.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.22.4)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (4.5.0)\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.10)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (4.9.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fairseq) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fairseq) (16.0.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->fairseq) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fairseq) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=11170782 sha256=0eafb1cb1e8430f66b01b3b847c624faf06909ae207a2d50ab00172b1b05fdaf\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=9134471097f4b9b7afc037a276b4d9e4ad69d397369e5a40e32e973e43ffa484\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "Installing collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 bitarray-2.7.4 colorama-0.4.6 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.7.0 sacrebleu-2.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2022.10.31)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.65.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=912f35ca7b880dd5922fb34a0521e7a1a84a7096b260c2dfff6e4cbf2dade7a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.0.53\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.1)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6\n"
          ]
        }
      ],
      "source": [
        "!pip install fairseq\n",
        "!pip install sentencepiece\n",
        "!pip install sacremoses\n",
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgk2LHivDQJX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertModel\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download BERT multilingual base model & BERT Tokenizer"
      ],
      "metadata": {
        "id": "I3m912CQf7jJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "12e080efa2a14502b70ce9b99677d276",
            "e8eb9643057a44918cfb6fa09732b9f2",
            "a22c50f3e77f446fa49df97ea0144b31",
            "f2bccc0ff42b4aa6a2dabb2e92c5feab",
            "eee1f4f27e584adcbdbc68478f943bbc",
            "3a89840b12564e0888c3599ca7aa622a",
            "7742ae4354374b729621ea4c3cb842a9",
            "9611c81761f24592865318a61b61d9b3",
            "4db296b293fb4ba68e0b83f1f64a2150",
            "32f26cf5621545dbbec2c8b5b3005303",
            "cb0120a618814ee29f03a5050d6abe11",
            "5e6cfeefcd074cb78eb12f50860da187",
            "ab6f293a6f8648838b1bd5aef413c0b5",
            "dbb589f1d9764471a59b32b84df977c0",
            "7dd40ab4b5da43dbba2a8718ecb1d3c9",
            "dc3715d6dd474193b989136d9427daee",
            "54e7cc54a127470587fd4b6250ddd8b1",
            "3f442584f0914d7eb76b294fb7ca4e06",
            "1159f687662f4642abdd4a04985934f7",
            "a84f9530a557458a80f70bba12810400",
            "0a5beb9c34ef47fcac17a99c58d01d2c",
            "8cb7acee2a144897bf1f917b9bdc37d5",
            "9afa4ae96ab545198a216c9cd6ac69e6",
            "e9e979ea530641e99656fbdd71b481de",
            "7e330f9a13144146ad636e54b6599d71",
            "11413c3d73bd4f27a34afa84cfc31a94",
            "ec523e0fb2524c529f1c3c5c319a1b25",
            "a6127714925f427b9d77b38b267edfa0",
            "3ba9439780c74035bae481e7d9333747",
            "a340d3fe222a4f4ca217da49e6d8c8c1",
            "314d255f58a248848640465f1f97e9f8",
            "5ae15d09fbf5463a89ecf8b890e77182",
            "d0c0773954274f43854a0a6101bcd6c6",
            "5c94ab2d539d4e59952b788bef16a285",
            "924a5ea11f0a4a7b82e5a3cf7e526a18",
            "11987db2c51641c98175af6c6357cc93",
            "8e25f496011144319a35e64992d06c0c",
            "30f936b6b3b0470eb4b555a63079bf86",
            "664f15bee36242b6b2cef12960d51c8e",
            "888f4b42fcb84363807caf83bfeb48b5",
            "73d44e1179954f4593fdcc1b38b308e0",
            "b6fc7bfcea1d400589b0ae763c7615a1",
            "a4c17a172d9e4b2d9b59b5f17be000a2",
            "2d629ade586b450d808d1ead295e389b"
          ]
        },
        "id": "IVsRNLUfDVls",
        "outputId": "7eec01d1-79db-439c-825a-00e9e8fd74d4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12e080efa2a14502b70ce9b99677d276",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e6cfeefcd074cb78eb12f50860da187",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9afa4ae96ab545198a216c9cd6ac69e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c94ab2d539d4e59952b788bef16a285",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "model = BertModel.from_pretrained(\"bert-base-multilingual-cased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Parallel Data"
      ],
      "metadata": {
        "id": "kcXrvvTqgD0L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxitXs1UDXUv",
        "outputId": "1a024b9d-7588-4727-b21f-5afa0332ac0f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-62d5c45b8041>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  train_en = pd.read_csv('/content/drive/MyDrive/DataSets/NMT/train.en' , sep='\\r\\n' , names = ['text'])\n",
            "<ipython-input-8-62d5c45b8041>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  train_fa = pd.read_csv('/content/drive/MyDrive/DataSets/NMT/train.fa' , sep='\\r\\n' , names = ['text'])\n",
            "<ipython-input-8-62d5c45b8041>:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  valid_en = pd.read_csv('/content/drive/MyDrive/DataSets/NMT/valid.en' , sep='\\r\\n' , names = ['text'])\n",
            "<ipython-input-8-62d5c45b8041>:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  valid_fa = pd.read_csv('/content/drive/MyDrive/DataSets/NMT/valid.fa' , sep='\\r\\n' , names = ['text'])\n",
            "<ipython-input-8-62d5c45b8041>:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  test_en = pd.read_csv('/content/drive/MyDrive/DataSets/NMT/test.en' , sep='\\r\\n' , names = ['text'])\n",
            "<ipython-input-8-62d5c45b8041>:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  test_fa = pd.read_csv('/content/drive/MyDrive/DataSets/NMT/test.fa' , sep='\\r\\n' , names = ['text'])\n"
          ]
        }
      ],
      "source": [
        "train_en = pd.read_csv('/content/drive/MyDrive/DataSets/NMT/train.en' , sep='\\r\\n' , names = ['text'])\n",
        "train_fa = pd.read_csv('/content/drive/MyDrive/DataSets/NMT/train.fa' , sep='\\r\\n' , names = ['text'])\n",
        "\n",
        "valid_en = pd.read_csv('/content/drive/MyDrive/DataSets/NMT/valid.en' , sep='\\r\\n' , names = ['text'])\n",
        "valid_fa = pd.read_csv('/content/drive/MyDrive/DataSets/NMT/valid.fa' , sep='\\r\\n' , names = ['text'])\n",
        "\n",
        "test_en = pd.read_csv('/content/drive/MyDrive/DataSets/NMT/test.en' , sep='\\r\\n' , names = ['text'])\n",
        "test_fa = pd.read_csv('/content/drive/MyDrive/DataSets/NMT/test.fa' , sep='\\r\\n' , names = ['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFGPq-U-EkLr",
        "outputId": "c8c5442b-9786-4804-842a-b086515fb8cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 670000 entries, 0 to 669999\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   text    670000 non-null  object\n",
            "dtypes: object(1)\n",
            "memory usage: 5.1+ MB\n"
          ]
        }
      ],
      "source": [
        "train_en.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxeQhc_gEkQg",
        "outputId": "9cb26635-ef93-48d6-be7e-a731d071c4d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 670000 entries, 0 to 669999\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   text    670000 non-null  object\n",
            "dtypes: object(1)\n",
            "memory usage: 5.1+ MB\n"
          ]
        }
      ],
      "source": [
        "train_fa.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process & Tokenize en/fa Data using BERT Tokenizer\n"
      ],
      "metadata": {
        "id": "LVgQSHsngWZ1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfzB9sKoEkaG"
      },
      "outputs": [],
      "source": [
        "!mkdir -p \"./tokenized_data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQ8T7YJEEkew"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/tokenized_data/train.en\" , 'w') as train_en_tokenized:\n",
        "  for line in train_en[\"text\"]:\n",
        "    tokens = tokenizer.encode(line, add_special_tokens=False)\n",
        "    words = tokenizer.convert_ids_to_tokens(tokens)\n",
        "    train_en_tokenized.write(\" \".join(words))\n",
        "    train_en_tokenized.write('\\n')\n",
        "\n",
        "with open(\"/content/tokenized_data/train.fa\" , 'w') as train_fa_tokenized:\n",
        "  for line in train_fa[\"text\"]:\n",
        "    tokens = tokenizer.encode(line, add_special_tokens=False)\n",
        "    words = tokenizer.convert_ids_to_tokens(tokens)\n",
        "    train_fa_tokenized.write(\" \".join(words))\n",
        "    train_fa_tokenized.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iwb8p9PBEkjp"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/tokenized_data/valid.en\" , 'w') as valid_en_tokenized:\n",
        "  for line in valid_en[\"text\"]:\n",
        "    tokens = tokenizer.encode(line, add_special_tokens=False)\n",
        "    words = tokenizer.convert_ids_to_tokens(tokens)\n",
        "    valid_en_tokenized.write(\" \".join(words))\n",
        "    valid_en_tokenized.write('\\n')\n",
        "\n",
        "with open(\"/content/tokenized_data/valid.fa\" , 'w') as valid_fa_tokenized:\n",
        "  for line in valid_fa[\"text\"]:\n",
        "    tokens = tokenizer.encode(line, add_special_tokens=False)\n",
        "    words = tokenizer.convert_ids_to_tokens(tokens)\n",
        "    valid_fa_tokenized.write(\" \".join(words))\n",
        "    valid_fa_tokenized.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ozvj3705EkoW"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/tokenized_data/test.en\" , 'w') as test_en_tokenized:\n",
        "  for line in test_en[\"text\"]:\n",
        "    tokens = tokenizer.encode(line, add_special_tokens=False)\n",
        "    words = tokenizer.convert_ids_to_tokens(tokens)\n",
        "    test_en_tokenized.write(\" \".join(words))\n",
        "    test_en_tokenized.write('\\n')\n",
        "\n",
        "with open(\"/content/tokenized_data/test.fa\" , 'w') as test_fa_tokenized:\n",
        "  for line in test_fa[\"text\"]:\n",
        "    tokens = tokenizer.encode(line, add_special_tokens=False)\n",
        "    words = tokenizer.convert_ids_to_tokens(tokens)\n",
        "    test_fa_tokenized.write(\" \".join(words))\n",
        "    test_fa_tokenized.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmoQ2BOVE1T9",
        "outputId": "8ff3e0ba-7bf9-46b5-db88-7f2f61d3d380"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "North W ##azi ##rista ##n operation kills 50 more militants\n",
            "PE ##SH ##A ##WA ##R - The on - going ##mil ##itar ##y operation in North W ##azi ##rista ##nki ##lle ##d at least 50 more suspected militants June 17 , Geo News reported .\n",
            "The Pakistani Air Force conducted airs ##tri ##kes against militant hide ##outs in Mir Ali and other areas of the agency , destroying at least eight , media reported .\n",
            "A day earlier , at least 27 militants were reported dead after jet ##s pound ##ed militant hide ##outs in Shaw ##al .\n",
            "Meanwhile , a roads ##ide bl ##ast on Bang ##idar road in the G ##hul ##lam Khan area June 16 killed six security personnel and wounded three others , according to officials .\n",
            "مرگ 50 س ##تی ##زه جو ##ی دیگر در عملیات وزیر ##ستان شمالی\n",
            "پیش ##اور - به گزارش جی ##و نیو ##ز , عملیات ادامه دار ارتش در وزیر ##ستان شمالی ##من ##جر به مرگ دست کم 50 س ##تی ##زه جو ##ی م ##ظ ##نون دیگر در روز 17 ژوئن شد .\n",
            "به گزارش ر ##سان ##هها , نیروی هوایی پاکستان حمل ##ات هوایی را علیه م ##خ ##فی ##گاه های س ##تی ##زه جو ##یی در می ##رع ##لی و نو ##اح ##ی دیگر منطقه انجام داد و دست کم ه ##شت م ##خ ##فی ##گاه را وی ##ران کرد .\n",
            "یک روز پیش ##تر گزارش شده بود که دست کم 27 س ##تی ##زه جو در پی ب ##م ##بار ##ان م ##خ ##فی ##گاه های س ##تی ##زه جو ##یان در ش ##وال توسط ج ##ت های ب ##م ##ب ا ##ف ##کن , کشته شدند .\n",
            "در ضمن , م ##س ##ئول ##ان گفت ##ند که یک ان ##ف ##جار کنار ##جا ##ده ای در روز 16 ژوئن در خیابان بن ##گی ##دار ناحیه غ ##لام خان جان شش پر ##سن ##ل امنیت ##ی را گرفت و سه تن دیگر را ز ##خم ##ی کرد .\n"
          ]
        }
      ],
      "source": [
        "!head ./tokenized_data/train.en -n 5\n",
        "!head ./tokenized_data/train.fa -n 5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre Process data using fariseq-preprocess"
      ],
      "metadata": {
        "id": "V8BGr7m2gypb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0gGysbKE1gG",
        "outputId": "d380d13f-b7c1-45e7-f988-ddd2557f5809"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-06-09 08:31:53.063691: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-06-09 08:31:56 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='en', target_lang='fa', trainpref='./tokenized_data/train', validpref='./tokenized_data/valid', testpref='./tokenized_data/test', align_suffix=None, destdir='./data_bin/', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict=None, nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=True, only_source=False, padding_factor=8, workers=1, dict_only=False)\n",
            "2023-06-09 08:33:23 | INFO | fairseq_cli.preprocess | [en] Dictionary: 33216 types\n",
            "2023-06-09 08:35:27 | INFO | fairseq_cli.preprocess | [en] ./tokenized_data/train.en: 670000 sents, 18047235 tokens, 0.0% replaced (by <unk>)\n",
            "2023-06-09 08:35:27 | INFO | fairseq_cli.preprocess | [en] Dictionary: 33216 types\n",
            "2023-06-09 08:35:28 | INFO | fairseq_cli.preprocess | [en] ./tokenized_data/valid.en: 4000 sents, 53776 tokens, 0.0093% replaced (by <unk>)\n",
            "2023-06-09 08:35:28 | INFO | fairseq_cli.preprocess | [en] Dictionary: 33216 types\n",
            "2023-06-09 08:35:29 | INFO | fairseq_cli.preprocess | [en] ./tokenized_data/test.en: 10000 sents, 124836 tokens, 0.0296% replaced (by <unk>)\n",
            "2023-06-09 08:35:29 | INFO | fairseq_cli.preprocess | [fa] Dictionary: 33216 types\n",
            "2023-06-09 08:38:40 | INFO | fairseq_cli.preprocess | [fa] ./tokenized_data/train.fa: 670000 sents, 23941952 tokens, 0.0% replaced (by <unk>)\n",
            "2023-06-09 08:38:40 | INFO | fairseq_cli.preprocess | [fa] Dictionary: 33216 types\n",
            "2023-06-09 08:38:41 | INFO | fairseq_cli.preprocess | [fa] ./tokenized_data/valid.fa: 4000 sents, 66139 tokens, 0.00151% replaced (by <unk>)\n",
            "2023-06-09 08:38:41 | INFO | fairseq_cli.preprocess | [fa] Dictionary: 33216 types\n",
            "2023-06-09 08:38:43 | INFO | fairseq_cli.preprocess | [fa] ./tokenized_data/test.fa: 10000 sents, 147543 tokens, 0.0% replaced (by <unk>)\n",
            "2023-06-09 08:38:43 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to ./data_bin/\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ./data_bin\n",
        "\n",
        "!fairseq-preprocess --source-lang en --target-lang fa  --joined-dictionary\\\n",
        "  --trainpref ./tokenized_data/train \\\n",
        "  --validpref ./tokenized_data/valid \\\n",
        "  --testpref ./tokenized_data/test \\\n",
        "  --destdir ./data_bin/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the weights of the embedding layer of the Bert Model with the appropriate format"
      ],
      "metadata": {
        "id": "Gh9ae1pxg9Ve"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFm5LXdQFAJE"
      },
      "outputs": [],
      "source": [
        "# Get the vocabulary size and embedding size\n",
        "vocab_size = model.config.vocab_size\n",
        "embedding_size = model.config.hidden_size\n",
        "\n",
        "# Extract the embedding weights from the model\n",
        "embedding_weights = model.get_input_embeddings().weight.data\n",
        "\n",
        "# Convert the embedding weights to a NumPy array\n",
        "embedding_weights_np = embedding_weights.numpy()\n",
        "\n",
        "# Save the embedding weights to a text file\n",
        "with open('embedding_weights.txt', 'w') as file:\n",
        "    file.write(str(vocab_size) + ' ' + str(embedding_size) + '\\n')\n",
        "    for i in range(vocab_size):\n",
        "        word = tokenizer.convert_ids_to_tokens(i)\n",
        "        file.write(word + ' ')\n",
        "        for value in embedding_weights_np[i]:\n",
        "            file.write(str(value) + ' ')\n",
        "        file.write('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model using fairseq-train & Using the weights of the embedding layer as the initial value of the Model weights"
      ],
      "metadata": {
        "id": "c-tepTayh0ss"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqtaX0THFATs",
        "outputId": "dd7d9b91-5efa-4788-db4f-eacbe885b5ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-06-09 09:57:57.512184: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-06-09 09:57:58 | INFO | numexpr.utils | NumExpr defaulting to 2 threads.\n",
            "2023-06-09 09:58:06 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './data_bin/logs1', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 5, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './data_bin/checkpoints1/', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir='./data_bin/logs1', wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=True, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4096, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='lstm', max_epoch=5, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.002], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='./data_bin/checkpoints1/', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='bleu', maximize_best_checkpoint_metric=True, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, share_decoder_input_output_embed=False, share_all_embeddings=True, data='./data_bin/', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, max_source_positions=1024, max_target_positions=1024, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_print_samples=True, label_smoothing=0.2, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.0001, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=0.0025, pad=1, eos=2, unk=3, encoder_embed_path='/content/embedding_weights.txt', decoder_embed_path='/content/embedding_weights.txt', encoder_embed_dim=768, decoder_embed_dim=768, decoder_out_embed_dim=768, encoder_layers=1, decoder_layers=1, dropout=0.25, no_seed_provided=False, encoder_freeze_embed=False, encoder_hidden_size=768, encoder_bidirectional=False, encoder_dropout_in=0.25, encoder_dropout_out=0.25, decoder_freeze_embed=False, decoder_hidden_size=768, decoder_attention='1', decoder_dropout_in=0.25, decoder_dropout_out=0.25, adaptive_softmax_cutoff='10000,50000,200000', _name='lstm'), 'task': {'_name': 'translation', 'data': './data_bin/', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.2, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 0.0025, 'lr': [0.002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2023-06-09 09:58:06 | INFO | fairseq.tasks.translation | [en] dictionary: 33216 types\n",
            "2023-06-09 09:58:06 | INFO | fairseq.tasks.translation | [fa] dictionary: 33216 types\n",
            "2023-06-09 09:58:33 | INFO | fairseq.utils | found 33206/33216 types in embedding file\n",
            "2023-06-09 09:58:34 | INFO | fairseq_cli.train | LSTMModel(\n",
            "  (encoder): LSTMEncoder(\n",
            "    (dropout_in_module): FairseqDropout()\n",
            "    (dropout_out_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(33216, 768, padding_idx=1)\n",
            "    (lstm): LSTM(768, 768)\n",
            "  )\n",
            "  (decoder): LSTMDecoder(\n",
            "    (dropout_in_module): FairseqDropout()\n",
            "    (dropout_out_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(33216, 768, padding_idx=1)\n",
            "    (layers): ModuleList(\n",
            "      (0): LSTMCell(1536, 768)\n",
            "    )\n",
            "    (attention): AttentionLayer(\n",
            "      (input_proj): Linear(in_features=768, out_features=768, bias=False)\n",
            "      (output_proj): Linear(in_features=1536, out_features=768, bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2023-06-09 09:58:34 | INFO | fairseq_cli.train | task: TranslationTask\n",
            "2023-06-09 09:58:34 | INFO | fairseq_cli.train | model: LSTMModel\n",
            "2023-06-09 09:58:34 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2023-06-09 09:58:34 | INFO | fairseq_cli.train | num. shared model params: 39,088,128 (num. trained: 39,088,128)\n",
            "2023-06-09 09:58:34 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2023-06-09 09:58:34 | INFO | fairseq.data.data_utils | loaded 4,000 examples from: ./data_bin/valid.en-fa.en\n",
            "2023-06-09 09:58:34 | INFO | fairseq.data.data_utils | loaded 4,000 examples from: ./data_bin/valid.en-fa.fa\n",
            "2023-06-09 09:58:34 | INFO | fairseq.tasks.translation | ./data_bin/ valid en-fa 4000 examples\n",
            "2023-06-09 09:58:38 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight\n",
            "2023-06-09 09:58:38 | INFO | fairseq.trainer | detected shared parameter: decoder.attention.input_proj.bias <- decoder.attention.output_proj.bias\n",
            "2023-06-09 09:58:38 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2023-06-09 09:58:38 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.748 GB ; name = Tesla T4                                \n",
            "2023-06-09 09:58:38 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2023-06-09 09:58:38 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2023-06-09 09:58:38 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = None\n",
            "2023-06-09 09:58:38 | INFO | fairseq.trainer | Preparing to load checkpoint ./data_bin/checkpoints1/checkpoint_last.pt\n",
            "2023-06-09 09:58:38 | INFO | fairseq.trainer | No existing checkpoint found ./data_bin/checkpoints1/checkpoint_last.pt\n",
            "2023-06-09 09:58:38 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2023-06-09 09:58:38 | INFO | fairseq.data.data_utils | loaded 670,000 examples from: ./data_bin/train.en-fa.en\n",
            "2023-06-09 09:58:38 | INFO | fairseq.data.data_utils | loaded 670,000 examples from: ./data_bin/train.en-fa.fa\n",
            "2023-06-09 09:58:38 | INFO | fairseq.tasks.translation | ./data_bin/ train en-fa 670000 examples\n",
            "2023-06-09 09:58:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6296\n",
            "epoch 001:   0% 0/6296 [00:00<?, ?it/s]2023-06-09 09:58:38 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2023-06-09 09:58:38 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "/usr/local/lib/python3.10/dist-packages/fairseq/utils.py:374: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  warnings.warn(\n",
            "epoch 001:   0% 6/6296 [00:01<17:11,  6.10it/s]2023-06-09 09:58:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0\n",
            "epoch 001: 100% 6295/6296 [16:38<00:00,  6.76it/s, loss=6.469, nll_loss=3.636, ppl=12.43, wps=23925.1, ups=6.24, wpb=3831.2, bsz=101.8, num_updates=6200, lr=0.00160644, gnorm=0.265, loss_scale=64, train_wall=16, gb_free=12.7, wall=984]2023-06-09 10:15:17 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   0% 0/27 [00:00<?, ?it/s]\u001b[A2023-06-09 10:15:18 | INFO | fairseq.tasks.translation | example hypothesis: از طریق\n",
            "2023-06-09 10:15:18 | INFO | fairseq.tasks.translation | example reference: خدا ##حافظ,\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   4% 1/27 [00:00<00:20,  1.24it/s]\u001b[A2023-06-09 10:15:19 | INFO | fairseq.tasks.translation | example hypothesis: غ ##م ##گی ##ن.\n",
            "2023-06-09 10:15:19 | INFO | fairseq.tasks.translation | example reference: هو ##م تن ##بل.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   7% 2/27 [00:01<00:18,  1.34it/s]\u001b[A2023-06-09 10:15:20 | INFO | fairseq.tasks.translation | example hypothesis: اما حال ##ا من ه ##ست ##م.\n",
            "2023-06-09 10:15:20 | INFO | fairseq.tasks.translation | example reference: اما ال ##ان انجام داده - ام.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  11% 3/27 [00:02<00:17,  1.33it/s]\u001b[A2023-06-09 10:15:20 | INFO | fairseq.tasks.translation | example hypothesis: میتوان ##یم بعد از آن میتوان ##یم بعضی وقت را مل ##اقات ک ##نی ##م?\n",
            "2023-06-09 10:15:20 | INFO | fairseq.tasks.translation | example reference: آیا میتوان ##یم زمانی مل ##اقات ک ##نی ##م?\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  15% 4/27 [00:03<00:17,  1.31it/s]\u001b[A2023-06-09 10:15:21 | INFO | fairseq.tasks.translation | example hypothesis: خوب, من آنجا ه ##ست ##م.\n",
            "2023-06-09 10:15:21 | INFO | fairseq.tasks.translation | example reference: خوب ##ه, من آنجا خ ##وا ##هم بود.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  19% 5/27 [00:03<00:15,  1.39it/s]\u001b[A2023-06-09 10:15:22 | INFO | fairseq.tasks.translation | example hypothesis: با ##ش ##ه, بیست و هفت ##م خوب است.\n",
            "2023-06-09 10:15:22 | INFO | fairseq.tasks.translation | example reference: با ##ش ##ه, بیست و هفت ##م خوب است.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  22% 6/27 [00:04<00:15,  1.39it/s]\u001b[A2023-06-09 10:15:22 | INFO | fairseq.tasks.translation | example hypothesis: بیست و سوم? احمد با ##ش ##ه\n",
            "2023-06-09 10:15:22 | INFO | fairseq.tasks.translation | example reference: بیست و سوم? آ ##م خوب است,\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  26% 7/27 [00:05<00:14,  1.41it/s]\u001b[A2023-06-09 10:15:23 | INFO | fairseq.tasks.translation | example hypothesis: \"احمد چ ##طور, اول اکتبر.\n",
            "2023-06-09 10:15:23 | INFO | fairseq.tasks.translation | example reference: آ ##ه, اول اکتبر چه - طور است?\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  30% 8/27 [00:05<00:13,  1.37it/s]\u001b[A2023-06-09 10:15:24 | INFO | fairseq.tasks.translation | example hypothesis: شما آخر هفت ##ه ی آخر هفت ##ه می ##خ ##وا ##هی ##د?\n",
            "2023-06-09 10:15:24 | INFO | fairseq.tasks.translation | example reference: شما این هفت ##ه به ها ##وا ##یی می ##روی ##د, ها ##ن?\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  33% 9/27 [00:06<00:13,  1.36it/s]\u001b[A2023-06-09 10:15:24 | INFO | fairseq.tasks.translation | example hypothesis: \"وقتی د ##قی ##قا د ##قی ##قا می ##خ ##وا ##هی ##د دست ##رسی داشته با ##شید.\n",
            "2023-06-09 10:15:24 | INFO | fairseq.tasks.translation | example reference: او ##ه ##وم شما د ##قی ##قا چه زمانی در دست ##رس ه ##ستی ##د.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  37% 10/27 [00:07<00:11,  1.50it/s]\u001b[A2023-06-09 10:15:25 | INFO | fairseq.tasks.translation | example hypothesis: من می ##خ ##وا ##هم بین دو و چهار و سی و سی و چهار,\n",
            "2023-06-09 10:15:25 | INFO | fairseq.tasks.translation | example reference: بین دو تا چهار و ن ##یم سر ##م ش ##لو ##غ است,\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  41% 11/27 [00:07<00:09,  1.64it/s]\u001b[A2023-06-09 10:15:26 | INFO | fairseq.tasks.translation | example hypothesis: احمد بل ##ه مانند من گفت ##م,\n",
            "2023-06-09 10:15:26 | INFO | fairseq.tasks.translation | example reference: خوب است, آ ##م بل ##ه, احتمال ##ا من گفت ##م,\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  44% 12/27 [00:08<00:08,  1.69it/s]\u001b[A2023-06-09 10:15:26 | INFO | fairseq.tasks.translation | example hypothesis: در چند هفت ##ه آ ##ینده زمانی که شما آزاد ه ##ستی ##د.\n",
            "2023-06-09 10:15:26 | INFO | fairseq.tasks.translation | example reference: زمانی در دو هفت ##هی آ ##ینده وجود دارد که شما آزاد با ##شی?\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  48% 13/27 [00:08<00:08,  1.71it/s]\u001b[A2023-06-09 10:15:27 | INFO | fairseq.tasks.translation | example hypothesis: خوب, خوب, من خ ##یلی خوب خ ##وا ##هم دید,\n",
            "2023-06-09 10:15:27 | INFO | fairseq.tasks.translation | example reference: عالی. برای من بسیار خوب خواهد شد, شما را می ##بین ##م,\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  52% 14/27 [00:09<00:07,  1.74it/s]\u001b[A2023-06-09 10:15:27 | INFO | fairseq.tasks.translation | example hypothesis: در حال حاضر ب ##د نیست اما من ن ##می ##خ ##وا ##هم ر ##یس ##ک را ب ##گیر ##م.\n",
            "2023-06-09 10:15:27 | INFO | fairseq.tasks.translation | example reference: این همین ال ##ان ب ##د نیست ولی من ن ##می ##خ ##وا ##هم ر ##یس ##ک ک ##ن ##م.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  56% 15/27 [00:09<00:06,  1.76it/s]\u001b[A2023-06-09 10:15:28 | INFO | fairseq.tasks.translation | example hypothesis: من می ##خ ##وا ##هم در هفت ##ه آ ##ینده به ج ##ز دو ##شن ##به.\n",
            "2023-06-09 10:15:28 | INFO | fairseq.tasks.translation | example reference: تمام هفت ##ه - ی آ ##ینده ک ##نف ##ران ##سه ##ایی دار ##م, به غیر از روز دو ##شن ##به.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  59% 16/27 [00:10<00:06,  1.73it/s]\u001b[A2023-06-09 10:15:28 | INFO | fairseq.tasks.translation | example hypothesis: اما \"احمد ##ی\", ص ##بح بیست و سوم, با شما دید ##م,\n",
            "2023-06-09 10:15:28 | INFO | fairseq.tasks.translation | example reference: اما, آ ##ه من ص ##بح بیست و سوم, میتوان ##م با شما مل ##اقات ک ##ن ##م,\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  63% 17/27 [00:10<00:05,  1.80it/s]\u001b[A2023-06-09 10:15:29 | INFO | fairseq.tasks.translation | example hypothesis: با ##ش ##ه, با ##ش ##ه, به ما اجازه ده ##ید و این کار را قبل از سی و سی و دوم انجام ده ##یم.\n",
            "2023-06-09 10:15:29 | INFO | fairseq.tasks.translation | example reference: خ ##ب, پس ب ##گذاری ##د آن را برای قبل از سی و یک ##م هم ##اه ##نگ ک ##نی ##م.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  67% 18/27 [00:11<00:05,  1.58it/s]\u001b[A2023-06-09 10:15:30 | INFO | fairseq.tasks.translation | example hypothesis: اگر ##چه برخی امکان وجود دارد, \"احمد\" قبل از ن ##اه ##ار یا ن ##اه ##ار در روز جمع ##ه?\n",
            "2023-06-09 10:15:30 | INFO | fairseq.tasks.translation | example reference: اگر ##چه احتمال دارد ام قبل از ن ##اه ##ار و یا حول و ##حو ##ش زمان ن ##اه ##ار روز جمع ##ه باشد?\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  70% 19/27 [00:12<00:04,  1.63it/s]\u001b[A2023-06-09 10:15:30 | INFO | fairseq.tasks.translation | example hypothesis: من در شهر ن ##خ ##وا ##هم بود.\n",
            "2023-06-09 10:15:30 | INFO | fairseq.tasks.translation | example reference: من او ##ه ##وم هفت ##م, در شهر ن ##خ ##وا ##هم بود. من باید به فی ##لا ##دل ##فی ##ا بر ##وم.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  74% 20/27 [00:12<00:04,  1.69it/s]\u001b[A2023-06-09 10:15:31 | INFO | fairseq.tasks.translation | example hypothesis: من روز جمع ##ه ش ##ان ##زدهم آوریل با شما دید ##ار خ ##وا ##هم کرد.\n",
            "2023-06-09 10:15:31 | INFO | fairseq.tasks.translation | example reference: من شما را در دفتر کار ##تان مل ##اقات خ ##وا ##هم کرد, روز جمع ##ه, ش ##ان ##زدهم آپ ##ری ##ل ساعت یک.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  78% 21/27 [00:13<00:03,  1.74it/s]\u001b[A2023-06-09 10:15:31 | INFO | fairseq.tasks.translation | example hypothesis: بنابراین, چ ##را این کار را انتخاب ن ##می ##کن ##ید. و \"احمد س ##عی می ##کن ##م آن ##مو ##قع گ ##رس ##نگ ##ی ک ##ن ##م.\n",
            "2023-06-09 10:15:31 | INFO | fairseq.tasks.translation | example reference: بنابراین, چ ##را شما یک زمانی را مشخص ن ##می ##کن ##ید. و من نیز برای گ ##رس ##نه شدن تلاش خ ##وا ##هم کرد.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  81% 22/27 [00:13<00:02,  1.77it/s]\u001b[A2023-06-09 10:15:32 | INFO | fairseq.tasks.translation | example hypothesis: بنابراین بیست و ه ##شت ##م خوب است. \"احمد هر زمان در عصر بیست و ه ##شت ##م خوب است.\n",
            "2023-06-09 10:15:32 | INFO | fairseq.tasks.translation | example reference: پس. بیست و ه ##شت ##م خوب خواهد بود. میدان ##ید, او ##ه ##وم هر زمانی, در بعد ##از ##ظهر بیست و ه ##شت ##م.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  85% 23/27 [00:14<00:02,  1.74it/s]\u001b[A2023-06-09 10:15:32 | INFO | fairseq.tasks.translation | example hypothesis: و من بعد از ساعت یا ##زد ##ه, یا بعد از ساعت یا ##زد ##ه, یا بعد از ساعت ##های بعد,\n",
            "2023-06-09 10:15:32 | INFO | fairseq.tasks.translation | example reference: و بعد از ساعت یا ##زد ##ه هم در دست ##رس خ ##وا ##هم بود, یا باز هم جمع ##ه بعدی هر زمانی قبل از سه,\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  89% 24/27 [00:15<00:01,  1.71it/s]\u001b[A2023-06-09 10:15:33 | INFO | fairseq.tasks.translation | example hypothesis: احمد گفت: \"احمد, دو برای من, من ن ##می ##دان ##م که چ ##قدر طول ##انی خ ##وا ##هی ##د بود.\n",
            "2023-06-09 10:15:33 | INFO | fairseq.tasks.translation | example reference: او ##ه ##وم, دو برای من عالی است او ##ه ##وم, من به ##درس ##تی ن ##می ##دان ##م که آ ##ه, شما چه مدت زمانی دست ##رس خ ##وا ##هی ##د بود.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  93% 25/27 [00:15<00:01,  1.73it/s]\u001b[A2023-06-09 10:15:34 | INFO | fairseq.tasks.translation | example hypothesis: و سپس روز سه ش ##ن ##به از روز پنج ش ##ن ##به به این ##جا ن ##خ ##وا ##هی ##د رفت تا روز جمع ##ه, همه روز در یک س ##مین ##ار ه ##ست ##م.\n",
            "2023-06-09 10:15:34 | INFO | fairseq.tasks.translation | example reference: و, آ ##ه و بعد از سه - ش ##ن ##به تا پنج ##شن ##به شما این ##جا ن ##خ ##وا ##هی ##د بود. جمع ##ه من تمام روز با س ##مین ##ار در ##گیر ه ##ست ##م,\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  96% 26/27 [00:16<00:00,  1.74it/s]\u001b[A2023-06-09 10:15:34 | INFO | fairseq.tasks.translation | example hypothesis: \"من ن ##می ##تو ##ان ##م به نظر ن ##می ##رس ##د که کد ##ام کد ##ام از این قانون برای ان ##حل ##ال ه ##ست ##م.\n",
            "2023-06-09 10:15:34 | INFO | fairseq.tasks.translation | example reference: آ ##ه به - نظر ن ##می ##رس ##د که من ب ##تو ##ان ##م کد ال ##کت ##ریکی را برای اجرا مه ##یا ک ##ن ##م, من نیاز دار ##م که آ ##ه با تو زمانی دوباره برای حدود بیش از دو ساعت, در این هفت ##ه مل ##اقات ک ##ن ##م. کی برای تو خوب است.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset: 100% 27/27 [00:16<00:00,  1.72it/s]\u001b[A\n",
            "                                                                        \u001b[A2023-06-09 10:15:34 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.186 | nll_loss 3.257 | ppl 9.56 | bleu 37.47 | wps 4009.3 | wpb 2449.6 | bsz 148.1 | num_updates 6295\n",
            "2023-06-09 10:15:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 6295 updates\n",
            "2023-06-09 10:15:34 | INFO | fairseq.trainer | Saving checkpoint to /content/data_bin/checkpoints1/checkpoint1.pt\n",
            "2023-06-09 10:15:37 | INFO | fairseq.trainer | Finished saving checkpoint to /content/data_bin/checkpoints1/checkpoint1.pt\n",
            "2023-06-09 10:15:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./data_bin/checkpoints1/checkpoint1.pt (epoch 1 @ 6295 updates, score 37.47) (writing took 11.02882469799988 seconds)\n",
            "2023-06-09 10:15:45 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2023-06-09 10:15:45 | INFO | train | epoch 001 | loss 7.039 | nll_loss 4.37 | ppl 20.67 | wps 23326.5 | ups 6.13 | wpb 3802.7 | bsz 106.3 | num_updates 6295 | lr 0.00159427 | gnorm 0.298 | loss_scale 64 | train_wall 974 | gb_free 12.7 | wall 1027\n",
            "2023-06-09 10:15:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6296\n",
            "epoch 002:   0% 0/6296 [00:00<?, ?it/s]2023-06-09 10:15:45 | INFO | fairseq.trainer | begin training epoch 2\n",
            "2023-06-09 10:15:45 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 002: 100% 6295/6296 [16:51<00:00,  7.83it/s, loss=6.158, nll_loss=3.247, ppl=9.49, wps=24322.8, ups=6.4, wpb=3801.2, bsz=113.3, num_updates=12500, lr=0.00113137, gnorm=0.254, loss_scale=64, train_wall=15, gb_free=12.9, wall=2024]2023-06-09 10:32:37 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:   0% 0/27 [00:00<?, ?it/s]\u001b[A2023-06-09 10:32:38 | INFO | fairseq.tasks.translation | example hypothesis: از طریق آن,\n",
            "2023-06-09 10:32:38 | INFO | fairseq.tasks.translation | example reference: خدا ##حافظ,\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:   4% 1/27 [00:00<00:18,  1.43it/s]\u001b[A2023-06-09 10:32:38 | INFO | fairseq.tasks.translation | example hypothesis: ا ##فت ##خار ک ##نید.\n",
            "2023-06-09 10:32:38 | INFO | fairseq.tasks.translation | example reference: هو ##م تن ##بل.\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:   7% 2/27 [00:01<00:15,  1.60it/s]\u001b[A2023-06-09 10:32:39 | INFO | fairseq.tasks.translation | example hypothesis: اما اکنون من انجام می ##دهم.\n",
            "2023-06-09 10:32:39 | INFO | fairseq.tasks.translation | example reference: اما ال ##ان انجام داده - ام.\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  11% 3/27 [00:01<00:14,  1.64it/s]\u001b[A2023-06-09 10:32:40 | INFO | fairseq.tasks.translation | example hypothesis: آیا میتوان ##یم آن زمان را مل ##اقات ک ##نی ##م?\n",
            "2023-06-09 10:32:40 | INFO | fairseq.tasks.translation | example reference: آیا میتوان ##یم زمانی مل ##اقات ک ##نی ##م?\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  15% 4/27 [00:02<00:14,  1.63it/s]\u001b[A2023-06-09 10:32:40 | INFO | fairseq.tasks.translation | example hypothesis: با ##ش ##ه, من آنجا خ ##وا ##هم بود.\n",
            "2023-06-09 10:32:40 | INFO | fairseq.tasks.translation | example reference: خوب ##ه, من آنجا خ ##وا ##هم بود.\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  19% 5/27 [00:02<00:12,  1.74it/s]\u001b[A2023-06-09 10:32:41 | INFO | fairseq.tasks.translation | example hypothesis: با ##ش ##ه, بیست و هفت ##م خوب است.\n",
            "2023-06-09 10:32:41 | INFO | fairseq.tasks.translation | example reference: با ##ش ##ه, بیست و هفت ##م خوب است.\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  22% 6/27 [00:03<00:11,  1.77it/s]\u001b[A2023-06-09 10:32:41 | INFO | fairseq.tasks.translation | example hypothesis: بیست و سوم? \"\n",
            "2023-06-09 10:32:41 | INFO | fairseq.tasks.translation | example reference: بیست و سوم? آ ##م خوب است,\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  26% 7/27 [00:04<00:10,  1.82it/s]\u001b[A2023-06-09 10:32:42 | INFO | fairseq.tasks.translation | example hypothesis: \"احمد چ ##طور در ##بار ##ه چ ##طور است.\n",
            "2023-06-09 10:32:42 | INFO | fairseq.tasks.translation | example reference: آ ##ه, اول اکتبر چه - طور است?\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  30% 8/27 [00:04<00:10,  1.78it/s]\u001b[A2023-06-09 10:32:42 | INFO | fairseq.tasks.translation | example hypothesis: آیا این آخر هفت ##ه به ها ##وا ##یی می ##خ ##وا ##هی ##د?\n",
            "2023-06-09 10:32:42 | INFO | fairseq.tasks.translation | example reference: شما این هفت ##ه به ها ##وا ##یی می ##روی ##د, ها ##ن?\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  33% 9/27 [00:05<00:10,  1.78it/s]\u001b[A2023-06-09 10:32:43 | INFO | fairseq.tasks.translation | example hypothesis: \"احمد زمانی که می ##خ ##وا ##هی ##د در دست ##رس قرار گ ##یر ##د.\n",
            "2023-06-09 10:32:43 | INFO | fairseq.tasks.translation | example reference: او ##ه ##وم شما د ##قی ##قا چه زمانی در دست ##رس ه ##ستی ##د.\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  37% 10/27 [00:05<00:09,  1.80it/s]\u001b[A2023-06-09 10:32:43 | INFO | fairseq.tasks.translation | example hypothesis: من می ##خ ##وا ##هم بین دو تا چهار سال ا ##تو ##بو ##س ه ##ست ##م,\n",
            "2023-06-09 10:32:43 | INFO | fairseq.tasks.translation | example reference: بین دو تا چهار و ن ##یم سر ##م ش ##لو ##غ است,\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  41% 11/27 [00:06<00:08,  1.85it/s]\u001b[A2023-06-09 10:32:44 | INFO | fairseq.tasks.translation | example hypothesis: \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\n",
            "2023-06-09 10:32:44 | INFO | fairseq.tasks.translation | example reference: خوب است, آ ##م بل ##ه, احتمال ##ا من گفت ##م,\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  44% 12/27 [00:06<00:08,  1.79it/s]\u001b[A2023-06-09 10:32:44 | INFO | fairseq.tasks.translation | example hypothesis: در چند هفت ##ه آ ##ینده, زمانی که شما آزاد ه ##ستی ##د?\n",
            "2023-06-09 10:32:44 | INFO | fairseq.tasks.translation | example reference: زمانی در دو هفت ##هی آ ##ینده وجود دارد که شما آزاد با ##شی?\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  48% 13/27 [00:07<00:07,  1.76it/s]\u001b[A2023-06-09 10:32:45 | INFO | fairseq.tasks.translation | example hypothesis: عالی است که برای من کار خ ##وا ##هم کرد, من آن ##مو ##قع شما را می ##بین ##م\n",
            "2023-06-09 10:32:45 | INFO | fairseq.tasks.translation | example reference: عالی. برای من بسیار خوب خواهد شد, شما را می ##بین ##م,\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  52% 14/27 [00:08<00:07,  1.76it/s]\u001b[A2023-06-09 10:32:46 | INFO | fairseq.tasks.translation | example hypothesis: در حال حاضر ب ##د نیست, اما من ن ##می ##خ ##وا ##هم ر ##یس ##ک را ب ##گیر ##م.\n",
            "2023-06-09 10:32:46 | INFO | fairseq.tasks.translation | example reference: این همین ال ##ان ب ##د نیست ولی من ن ##می ##خ ##وا ##هم ر ##یس ##ک ک ##ن ##م.\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  56% 15/27 [00:08<00:06,  1.74it/s]\u001b[A2023-06-09 10:32:46 | INFO | fairseq.tasks.translation | example hypothesis: من می ##خ ##وا ##هم, \"ک ##نف ##ران ##س های هفت ##ه آ ##ینده به ج ##ز دو ##شن ##به.\"\n",
            "2023-06-09 10:32:46 | INFO | fairseq.tasks.translation | example reference: تمام هفت ##ه - ی آ ##ینده ک ##نف ##ران ##سه ##ایی دار ##م, به غیر از روز دو ##شن ##به.\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  59% 16/27 [00:09<00:06,  1.69it/s]\u001b[A2023-06-09 10:32:47 | INFO | fairseq.tasks.translation | example hypothesis: \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\"\n",
            "2023-06-09 10:32:47 | INFO | fairseq.tasks.translation | example reference: اما, آ ##ه من ص ##بح بیست و سوم, میتوان ##م با شما مل ##اقات ک ##ن ##م,\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  63% 17/27 [00:09<00:06,  1.60it/s]\u001b[A2023-06-09 10:32:48 | INFO | fairseq.tasks.translation | example hypothesis: با ##ش ##ه, \"احمد ##ی\" ب ##گذاری ##د س ##عی ک ##نی ##م این کار را انجام ده ##یم و این کار را انجام ده ##یم.\n",
            "2023-06-09 10:32:48 | INFO | fairseq.tasks.translation | example reference: خ ##ب, پس ب ##گذاری ##د آن را برای قبل از سی و یک ##م هم ##اه ##نگ ک ##نی ##م.\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  67% 18/27 [00:10<00:06,  1.35it/s]\u001b[A2023-06-09 10:32:49 | INFO | fairseq.tasks.translation | example hypothesis: احمد قبل از ن ##اه ##ار یا ن ##اه ##ار در روز جمع ##ه?\n",
            "2023-06-09 10:32:49 | INFO | fairseq.tasks.translation | example reference: اگر ##چه احتمال دارد ام قبل از ن ##اه ##ار و یا حول و ##حو ##ش زمان ن ##اه ##ار روز جمع ##ه باشد?\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  70% 19/27 [00:11<00:06,  1.33it/s]\u001b[A2023-06-09 10:32:49 | INFO | fairseq.tasks.translation | example hypothesis: احمد در هفت ##م گفت: \"من در شهر ن ##خ ##وا ##هم بود.\"\n",
            "2023-06-09 10:32:49 | INFO | fairseq.tasks.translation | example reference: من او ##ه ##وم هفت ##م, در شهر ن ##خ ##وا ##هم بود. من باید به فی ##لا ##دل ##فی ##ا بر ##وم.\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  74% 20/27 [00:12<00:05,  1.34it/s]\u001b[A2023-06-09 10:32:50 | INFO | fairseq.tasks.translation | example hypothesis: من شما را در دفتر شما مل ##اقات خ ##وا ##هم کرد, در ساعت ش ##ان ##زدهم آوریل.\n",
            "2023-06-09 10:32:50 | INFO | fairseq.tasks.translation | example reference: من شما را در دفتر کار ##تان مل ##اقات خ ##وا ##هم کرد, روز جمع ##ه, ش ##ان ##زدهم آپ ##ری ##ل ساعت یک.\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  78% 21/27 [00:13<00:04,  1.34it/s]\u001b[A2023-06-09 10:32:51 | INFO | fairseq.tasks.translation | example hypothesis: به همین دلیل, چ ##را یک وقت را انتخاب ن ##می ##کن ##ید و \"آ ##ی\" خ ##وا ##هم س ##عی می ##کن ##م آن ##مو ##قع گ ##رس ##نه باشد.\n",
            "2023-06-09 10:32:51 | INFO | fairseq.tasks.translation | example reference: بنابراین, چ ##را شما یک زمانی را مشخص ن ##می ##کن ##ید. و من نیز برای گ ##رس ##نه شدن تلاش خ ##وا ##هم کرد.\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  81% 22/27 [00:13<00:03,  1.32it/s]\u001b[A2023-06-09 10:32:52 | INFO | fairseq.tasks.translation | example hypothesis: به همین دلیل بیست و ه ##شت ##م خوب است. احمد هر وقت در عصر بیست و ه ##شت ##م.\n",
            "2023-06-09 10:32:52 | INFO | fairseq.tasks.translation | example reference: پس. بیست و ه ##شت ##م خوب خواهد بود. میدان ##ید, او ##ه ##وم هر زمانی, در بعد ##از ##ظهر بیست و ه ##شت ##م.\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  85% 23/27 [00:14<00:03,  1.28it/s]\u001b[A2023-06-09 10:32:53 | INFO | fairseq.tasks.translation | example hypothesis: و من بعد از ساعت یا ##زد ##ه و یا بعد از ساعت یا ##زد ##ه, و یا دوباره جمع ##ه آ ##ینده در دست ##رس خ ##وا ##هم بود.\n",
            "2023-06-09 10:32:53 | INFO | fairseq.tasks.translation | example reference: و بعد از ساعت یا ##زد ##ه هم در دست ##رس خ ##وا ##هم بود, یا باز هم جمع ##ه بعدی هر زمانی قبل از سه,\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  89% 24/27 [00:15<00:02,  1.32it/s]\u001b[A2023-06-09 10:32:53 | INFO | fairseq.tasks.translation | example hypothesis: \"احمد, دو نفر برای من کامل ##ا خوب است, من ن ##می ##دان ##م\" احمد د ##قی ##قا چ ##قدر طول می ##کش ##د. \"\n",
            "2023-06-09 10:32:53 | INFO | fairseq.tasks.translation | example reference: او ##ه ##وم, دو برای من عالی است او ##ه ##وم, من به ##درس ##تی ن ##می ##دان ##م که آ ##ه, شما چه مدت زمانی دست ##رس خ ##وا ##هی ##د بود.\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  93% 25/27 [00:16<00:01,  1.41it/s]\u001b[A2023-06-09 10:32:54 | INFO | fairseq.tasks.translation | example hypothesis: و \"احمد و بعد\" روز سه ش ##ن ##به از طریق پنج ش ##ن ##به به این ##جا ن ##می ##خ ##وا ##هم. جمع ##ه هم ##یشه در یک س ##مین ##ار ه ##ست ##م.\n",
            "2023-06-09 10:32:54 | INFO | fairseq.tasks.translation | example reference: و, آ ##ه و بعد از سه - ش ##ن ##به تا پنج ##شن ##به شما این ##جا ن ##خ ##وا ##هی ##د بود. جمع ##ه من تمام روز با س ##مین ##ار در ##گیر ه ##ست ##م,\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:  96% 26/27 [00:16<00:00,  1.50it/s]\u001b[A2023-06-09 10:32:54 | INFO | fairseq.tasks.translation | example hypothesis: \"من ن ##می ##تو ##ان ##م به نظر ن ##می ##رس ##د که این قانون به نظر ن ##می ##رس ##د که در حدود دو ساعت دیگر در این هفت ##ه با شما دید ##ار کند. زمانی که برای شما خوب خواهد بود.\n",
            "2023-06-09 10:32:54 | INFO | fairseq.tasks.translation | example reference: آ ##ه به - نظر ن ##می ##رس ##د که من ب ##تو ##ان ##م کد ال ##کت ##ریکی را برای اجرا مه ##یا ک ##ن ##م, من نیاز دار ##م که آ ##ه با تو زمانی دوباره برای حدود بیش از دو ساعت, در این هفت ##ه مل ##اقات ک ##ن ##م. کی برای تو خوب است.\n",
            "\n",
            "epoch 002 | valid on 'valid' subset: 100% 27/27 [00:17<00:00,  1.60it/s]\u001b[A\n",
            "                                                                        \u001b[A2023-06-09 10:32:54 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 6.024 | nll_loss 3.098 | ppl 8.56 | bleu 41.13 | wps 3907.8 | wpb 2449.6 | bsz 148.1 | num_updates 12591 | best_bleu 41.13\n",
            "2023-06-09 10:32:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 12591 updates\n",
            "2023-06-09 10:32:54 | INFO | fairseq.trainer | Saving checkpoint to /content/data_bin/checkpoints1/checkpoint2.pt\n",
            "2023-06-09 10:32:57 | INFO | fairseq.trainer | Finished saving checkpoint to /content/data_bin/checkpoints1/checkpoint2.pt\n",
            "2023-06-09 10:33:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./data_bin/checkpoints1/checkpoint2.pt (epoch 2 @ 12591 updates, score 41.13) (writing took 6.745757593000235 seconds)\n",
            "2023-06-09 10:33:01 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
            "2023-06-09 10:33:01 | INFO | train | epoch 002 | loss 6.264 | nll_loss 3.376 | ppl 10.38 | wps 23115.9 | ups 6.08 | wpb 3802.7 | bsz 106.4 | num_updates 12591 | lr 0.00112728 | gnorm 0.261 | loss_scale 64 | train_wall 987 | gb_free 12.9 | wall 2063\n",
            "2023-06-09 10:33:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6296\n",
            "epoch 003:   0% 0/6296 [00:00<?, ?it/s]2023-06-09 10:33:01 | INFO | fairseq.trainer | begin training epoch 3\n",
            "2023-06-09 10:33:01 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 003: 100% 6294/6296 [16:47<00:00,  7.19it/s, loss=6.043, nll_loss=3.104, ppl=8.6, wps=24316.5, ups=6.37, wpb=3814.9, bsz=100.6, num_updates=18800, lr=0.000922531, gnorm=0.251, loss_scale=128, train_wall=15, gb_free=12.7, wall=3057]2023-06-09 10:49:49 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:   0% 0/27 [00:00<?, ?it/s]\u001b[A2023-06-09 10:49:50 | INFO | fairseq.tasks.translation | example hypothesis: با توجه به اینکه ب ##خ ##وا ##هی ##د,\n",
            "2023-06-09 10:49:50 | INFO | fairseq.tasks.translation | example reference: خدا ##حافظ,\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:   4% 1/27 [00:00<00:17,  1.51it/s]\u001b[A2023-06-09 10:49:50 | INFO | fairseq.tasks.translation | example hypothesis: غ ##م ان ##گی ##ز.\n",
            "2023-06-09 10:49:50 | INFO | fairseq.tasks.translation | example reference: هو ##م تن ##بل.\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:   7% 2/27 [00:01<00:15,  1.61it/s]\u001b[A2023-06-09 10:49:51 | INFO | fairseq.tasks.translation | example hypothesis: اما اکنون من انجام می ##دهم.\n",
            "2023-06-09 10:49:51 | INFO | fairseq.tasks.translation | example reference: اما ال ##ان انجام داده - ام.\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  11% 3/27 [00:01<00:14,  1.65it/s]\u001b[A2023-06-09 10:49:52 | INFO | fairseq.tasks.translation | example hypothesis: میتوان ##یم آن زمان را مل ##اقات ک ##نی ##م?\n",
            "2023-06-09 10:49:52 | INFO | fairseq.tasks.translation | example reference: آیا میتوان ##یم زمانی مل ##اقات ک ##نی ##م?\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  15% 4/27 [00:02<00:14,  1.64it/s]\u001b[A2023-06-09 10:49:52 | INFO | fairseq.tasks.translation | example hypothesis: با ##ش ##ه, من آنجا خ ##وا ##هم بود.\n",
            "2023-06-09 10:49:52 | INFO | fairseq.tasks.translation | example reference: خوب ##ه, من آنجا خ ##وا ##هم بود.\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  19% 5/27 [00:02<00:12,  1.71it/s]\u001b[A2023-06-09 10:49:53 | INFO | fairseq.tasks.translation | example hypothesis: با ##ش ##ه, بیست و هفت ##م خوب است.\n",
            "2023-06-09 10:49:53 | INFO | fairseq.tasks.translation | example reference: با ##ش ##ه, بیست و هفت ##م خوب است.\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  22% 6/27 [00:03<00:12,  1.74it/s]\u001b[A2023-06-09 10:49:53 | INFO | fairseq.tasks.translation | example hypothesis: بیست و سوم? \"احمد با ##ش ##ه,\n",
            "2023-06-09 10:49:53 | INFO | fairseq.tasks.translation | example reference: بیست و سوم? آ ##م خوب است,\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  26% 7/27 [00:04<00:11,  1.78it/s]\u001b[A2023-06-09 10:49:54 | INFO | fairseq.tasks.translation | example hypothesis: \"احمد چ ##طور در ماه اکتبر چ ##طور است.\n",
            "2023-06-09 10:49:54 | INFO | fairseq.tasks.translation | example reference: آ ##ه, اول اکتبر چه - طور است?\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  30% 8/27 [00:04<00:10,  1.76it/s]\u001b[A2023-06-09 10:49:54 | INFO | fairseq.tasks.translation | example hypothesis: شما این آخر ##ه ##فته را به ها ##وا ##یی می ##بری ##د?\n",
            "2023-06-09 10:49:54 | INFO | fairseq.tasks.translation | example reference: شما این هفت ##ه به ها ##وا ##یی می ##روی ##د, ها ##ن?\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  33% 9/27 [00:05<00:10,  1.76it/s]\u001b[A2023-06-09 10:49:55 | INFO | fairseq.tasks.translation | example hypothesis: \"آ ##م وقتی که د ##قی ##قا در دست ##رس قرار می ##گیری ##د.\n",
            "2023-06-09 10:49:55 | INFO | fairseq.tasks.translation | example reference: او ##ه ##وم شما د ##قی ##قا چه زمانی در دست ##رس ه ##ستی ##د.\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  37% 10/27 [00:05<00:09,  1.78it/s]\u001b[A2023-06-09 10:49:55 | INFO | fairseq.tasks.translation | example hypothesis: من می ##خ ##وا ##هم بین دو و چهار نفر ش ##لو ##غ ه ##ست ##م,\n",
            "2023-06-09 10:49:55 | INFO | fairseq.tasks.translation | example reference: بین دو تا چهار و ن ##یم سر ##م ش ##لو ##غ است,\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  41% 11/27 [00:06<00:08,  1.83it/s]\u001b[A2023-06-09 10:49:56 | INFO | fairseq.tasks.translation | example hypothesis: \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\"\n",
            "2023-06-09 10:49:56 | INFO | fairseq.tasks.translation | example reference: خوب است, آ ##م بل ##ه, احتمال ##ا من گفت ##م,\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  44% 12/27 [00:07<00:09,  1.65it/s]\u001b[A2023-06-09 10:49:57 | INFO | fairseq.tasks.translation | example hypothesis: در چند هفت ##ه آ ##ینده زمانی که شما آزاد ه ##ستی ##د, وجود دارد?\n",
            "2023-06-09 10:49:57 | INFO | fairseq.tasks.translation | example reference: زمانی در دو هفت ##هی آ ##ینده وجود دارد که شما آزاد با ##شی?\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  48% 13/27 [00:07<00:09,  1.51it/s]\u001b[A2023-06-09 10:49:58 | INFO | fairseq.tasks.translation | example hypothesis: بسیار عالی ##ه که برای من کار خ ##وا ##هم کرد, آن ##مو ##قع شما را می ##بین ##م,\n",
            "2023-06-09 10:49:58 | INFO | fairseq.tasks.translation | example reference: عالی. برای من بسیار خوب خواهد شد, شما را می ##بین ##م,\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  52% 14/27 [00:08<00:09,  1.43it/s]\u001b[A2023-06-09 10:49:58 | INFO | fairseq.tasks.translation | example hypothesis: اکنون ب ##د نیست, اما من ن ##می ##خ ##وا ##هم ر ##یس ##ک ک ##ن ##م.\n",
            "2023-06-09 10:49:58 | INFO | fairseq.tasks.translation | example reference: این همین ال ##ان ب ##د نیست ولی من ن ##می ##خ ##وا ##هم ر ##یس ##ک ک ##ن ##م.\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  56% 15/27 [00:09<00:08,  1.39it/s]\u001b[A2023-06-09 10:49:59 | INFO | fairseq.tasks.translation | example hypothesis: من می ##خ ##وا ##هم که ب ##ج ##ز دو ##شن ##به آ ##ینده به ج ##ز دو ##شن ##به دو ##شن ##به.\n",
            "2023-06-09 10:49:59 | INFO | fairseq.tasks.translation | example reference: تمام هفت ##ه - ی آ ##ینده ک ##نف ##ران ##سه ##ایی دار ##م, به غیر از روز دو ##شن ##به.\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  59% 16/27 [00:10<00:08,  1.33it/s]\u001b[A2023-06-09 10:50:00 | INFO | fairseq.tasks.translation | example hypothesis: اما \"آ ##ه, من میتوان ##م ص ##بح بیست و سوم را مل ##اقات ک ##ن ##م,\n",
            "2023-06-09 10:50:00 | INFO | fairseq.tasks.translation | example reference: اما, آ ##ه من ص ##بح بیست و سوم, میتوان ##م با شما مل ##اقات ک ##ن ##م,\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  63% 17/27 [00:10<00:07,  1.35it/s]\u001b[A2023-06-09 10:50:01 | INFO | fairseq.tasks.translation | example hypothesis: با ##ش ##ه, \"خ ##ب, ب ##گذاری ##د س ##عی ک ##نی ##م س ##عی ک ##نی ##م و این کار را انجام ده ##یم.\n",
            "2023-06-09 10:50:01 | INFO | fairseq.tasks.translation | example reference: خ ##ب, پس ب ##گذاری ##د آن را برای قبل از سی و یک ##م هم ##اه ##نگ ک ##نی ##م.\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  67% 18/27 [00:12<00:07,  1.19it/s]\u001b[A2023-06-09 10:50:02 | INFO | fairseq.tasks.translation | example hypothesis: اگر چه احتمال ##ی وجود دارد, \"احمد قبل از ن ##اه ##ار یا ن ##اه ##ار روز جمع ##ه?\n",
            "2023-06-09 10:50:02 | INFO | fairseq.tasks.translation | example reference: اگر ##چه احتمال دارد ام قبل از ن ##اه ##ار و یا حول و ##حو ##ش زمان ن ##اه ##ار روز جمع ##ه باشد?\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  70% 19/27 [00:12<00:06,  1.30it/s]\u001b[A2023-06-09 10:50:02 | INFO | fairseq.tasks.translation | example hypothesis: من در شهر ن ##خ ##وا ##هم بود. من باید به فی ##لا ##دل ##فی ##ا بر ##وم.\n",
            "2023-06-09 10:50:02 | INFO | fairseq.tasks.translation | example reference: من او ##ه ##وم هفت ##م, در شهر ن ##خ ##وا ##هم بود. من باید به فی ##لا ##دل ##فی ##ا بر ##وم.\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  74% 20/27 [00:13<00:04,  1.42it/s]\u001b[A2023-06-09 10:50:03 | INFO | fairseq.tasks.translation | example hypothesis: من در دفتر شما با شما مل ##اقات خ ##وا ##هم کرد, ساعت ش ##ان ##زدهم آوریل.\n",
            "2023-06-09 10:50:03 | INFO | fairseq.tasks.translation | example reference: من شما را در دفتر کار ##تان مل ##اقات خ ##وا ##هم کرد, روز جمع ##ه, ش ##ان ##زدهم آپ ##ری ##ل ساعت یک.\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  78% 21/27 [00:13<00:03,  1.52it/s]\u001b[A2023-06-09 10:50:03 | INFO | fairseq.tasks.translation | example hypothesis: بنابراین, چ ##را شما یک زمان را انتخاب ن ##می ##کن ##ید و \"من س ##عی خ ##وا ##هم کرد که گ ##رس ##نگ ##ی ک ##ن ##م.\n",
            "2023-06-09 10:50:03 | INFO | fairseq.tasks.translation | example reference: بنابراین, چ ##را شما یک زمانی را مشخص ن ##می ##کن ##ید. و من نیز برای گ ##رس ##نه شدن تلاش خ ##وا ##هم کرد.\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  81% 22/27 [00:14<00:03,  1.59it/s]\u001b[A2023-06-09 10:50:04 | INFO | fairseq.tasks.translation | example hypothesis: به همین ترتیب بیست و ه ##شت ##م خوب است. \"\n",
            "2023-06-09 10:50:04 | INFO | fairseq.tasks.translation | example reference: پس. بیست و ه ##شت ##م خوب خواهد بود. میدان ##ید, او ##ه ##وم هر زمانی, در بعد ##از ##ظهر بیست و ه ##شت ##م.\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  85% 23/27 [00:14<00:02,  1.59it/s]\u001b[A2023-06-09 10:50:05 | INFO | fairseq.tasks.translation | example hypothesis: و من پس از ساعت یا ##زد ##ه, یا دوباره جمع ##ه آ ##ینده در دست ##رس خ ##وا ##هم بود.\n",
            "2023-06-09 10:50:05 | INFO | fairseq.tasks.translation | example reference: و بعد از ساعت یا ##زد ##ه هم در دست ##رس خ ##وا ##هم بود, یا باز هم جمع ##ه بعدی هر زمانی قبل از سه,\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  89% 24/27 [00:15<00:01,  1.59it/s]\u001b[A2023-06-09 10:50:05 | INFO | fairseq.tasks.translation | example hypothesis: \"آ ##م, دو نفر برای من\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\",\n",
            "2023-06-09 10:50:05 | INFO | fairseq.tasks.translation | example reference: او ##ه ##وم, دو برای من عالی است او ##ه ##وم, من به ##درس ##تی ن ##می ##دان ##م که آ ##ه, شما چه مدت زمانی دست ##رس خ ##وا ##هی ##د بود.\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  93% 25/27 [00:16<00:01,  1.62it/s]\u001b[A2023-06-09 10:50:06 | INFO | fairseq.tasks.translation | example hypothesis: و \"آ ##ه و سپس سه - ش ##ن ##به از سه ش ##ن ##به تا پنج ##شن ##به در این ##جا ن ##خ ##وا ##هم بود, من تمام روز را در س ##مین ##ار گ ##یر می ##کن ##م.\n",
            "2023-06-09 10:50:06 | INFO | fairseq.tasks.translation | example reference: و, آ ##ه و بعد از سه - ش ##ن ##به تا پنج ##شن ##به شما این ##جا ن ##خ ##وا ##هی ##د بود. جمع ##ه من تمام روز با س ##مین ##ار در ##گیر ه ##ست ##م,\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:  96% 26/27 [00:16<00:00,  1.66it/s]\u001b[A2023-06-09 10:50:06 | INFO | fairseq.tasks.translation | example hypothesis: \"من ن ##می ##تو ##ان ##م به نظر ن ##می ##رس ##د که کد ##ام یک از این قوانین را برای جمع آ ##وری م ##جد ##د من در حدود دو ساعت دیگر در این هفت ##ه بر ##آورد ##ه کنند. هنگامی که برای شما خوب خواهد بود.\n",
            "2023-06-09 10:50:06 | INFO | fairseq.tasks.translation | example reference: آ ##ه به - نظر ن ##می ##رس ##د که من ب ##تو ##ان ##م کد ال ##کت ##ریکی را برای اجرا مه ##یا ک ##ن ##م, من نیاز دار ##م که آ ##ه با تو زمانی دوباره برای حدود بیش از دو ساعت, در این هفت ##ه مل ##اقات ک ##ن ##م. کی برای تو خوب است.\n",
            "\n",
            "epoch 003 | valid on 'valid' subset: 100% 27/27 [00:17<00:00,  1.71it/s]\u001b[A\n",
            "                                                                        \u001b[A2023-06-09 10:50:06 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 5.953 | nll_loss 3.011 | ppl 8.06 | bleu 43.09 | wps 3891.7 | wpb 2449.6 | bsz 148.1 | num_updates 18887 | best_bleu 43.09\n",
            "2023-06-09 10:50:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 18887 updates\n",
            "2023-06-09 10:50:06 | INFO | fairseq.trainer | Saving checkpoint to /content/data_bin/checkpoints1/checkpoint3.pt\n",
            "2023-06-09 10:50:09 | INFO | fairseq.trainer | Finished saving checkpoint to /content/data_bin/checkpoints1/checkpoint3.pt\n",
            "2023-06-09 10:50:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./data_bin/checkpoints1/checkpoint3.pt (epoch 3 @ 18887 updates, score 43.09) (writing took 14.643305261999558 seconds)\n",
            "2023-06-09 10:50:21 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
            "2023-06-09 10:50:21 | INFO | train | epoch 003 | loss 6.095 | nll_loss 3.166 | ppl 8.98 | wps 23022.3 | ups 6.05 | wpb 3802.7 | bsz 106.4 | num_updates 18887 | lr 0.000920404 | gnorm 0.256 | loss_scale 128 | train_wall 984 | gb_free 12.8 | wall 3103\n",
            "2023-06-09 10:50:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6296\n",
            "epoch 004:   0% 0/6296 [00:00<?, ?it/s]2023-06-09 10:50:21 | INFO | fairseq.trainer | begin training epoch 4\n",
            "2023-06-09 10:50:21 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 004:  27% 1699/6296 [04:31<15:32,  4.93it/s, loss=6.016, nll_loss=3.067, ppl=8.38, wps=23515.4, ups=6.23, wpb=3774.5, bsz=112.4, num_updates=20500, lr=0.000883452, gnorm=0.255, loss_scale=128, train_wall=16, gb_free=12.8, wall=3361]2023-06-09 10:54:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0\n",
            "epoch 004: 100% 6295/6296 [16:44<00:00,  7.34it/s, loss=5.962, nll_loss=3.003, ppl=8.02, wps=22945.2, ups=6.08, wpb=3776.5, bsz=113.1, num_updates=25100, lr=0.000798405, gnorm=0.258, loss_scale=64, train_wall=16, gb_free=12.8, wall=4095]2023-06-09 11:07:06 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:   0% 0/27 [00:00<?, ?it/s]\u001b[A2023-06-09 11:07:07 | INFO | fairseq.tasks.translation | example hypothesis: با این م ##سا ##له,\n",
            "2023-06-09 11:07:07 | INFO | fairseq.tasks.translation | example reference: خدا ##حافظ,\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:   4% 1/27 [00:00<00:24,  1.06it/s]\u001b[A2023-06-09 11:07:07 | INFO | fairseq.tasks.translation | example hypothesis: کو ##چ ##ول ##و.\n",
            "2023-06-09 11:07:07 | INFO | fairseq.tasks.translation | example reference: هو ##م تن ##بل.\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:   7% 2/27 [00:01<00:21,  1.17it/s]\u001b[A2023-06-09 11:07:08 | INFO | fairseq.tasks.translation | example hypothesis: اما اکنون من انجام می ##دهم.\n",
            "2023-06-09 11:07:08 | INFO | fairseq.tasks.translation | example reference: اما ال ##ان انجام داده - ام.\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  11% 3/27 [00:02<00:19,  1.22it/s]\u001b[A2023-06-09 11:07:09 | INFO | fairseq.tasks.translation | example hypothesis: آیا میتوان ##یم یک وقت هم ##دی ##گر را مل ##اقات ک ##نی ##م?\n",
            "2023-06-09 11:07:09 | INFO | fairseq.tasks.translation | example reference: آیا میتوان ##یم زمانی مل ##اقات ک ##نی ##م?\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  15% 4/27 [00:03<00:19,  1.19it/s]\u001b[A2023-06-09 11:07:10 | INFO | fairseq.tasks.translation | example hypothesis: با ##ش ##ه, من آنجا ه ##ست ##م.\n",
            "2023-06-09 11:07:10 | INFO | fairseq.tasks.translation | example reference: خوب ##ه, من آنجا خ ##وا ##هم بود.\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  19% 5/27 [00:04<00:17,  1.25it/s]\u001b[A2023-06-09 11:07:11 | INFO | fairseq.tasks.translation | example hypothesis: با ##ش ##ه, بیست و هفت ##م خوب است.\n",
            "2023-06-09 11:07:11 | INFO | fairseq.tasks.translation | example reference: با ##ش ##ه, بیست و هفت ##م خوب است.\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  22% 6/27 [00:04<00:16,  1.27it/s]\u001b[A2023-06-09 11:07:11 | INFO | fairseq.tasks.translation | example hypothesis: بیست و سوم? \"\n",
            "2023-06-09 11:07:11 | INFO | fairseq.tasks.translation | example reference: بیست و سوم? آ ##م خوب است,\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  26% 7/27 [00:05<00:14,  1.35it/s]\u001b[A2023-06-09 11:07:12 | INFO | fairseq.tasks.translation | example hypothesis: \"\" \"\" \"\" \"\" \"\" \"\" \", اول اکتبر.\"\n",
            "2023-06-09 11:07:12 | INFO | fairseq.tasks.translation | example reference: آ ##ه, اول اکتبر چه - طور است?\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  30% 8/27 [00:06<00:13,  1.42it/s]\u001b[A2023-06-09 11:07:12 | INFO | fairseq.tasks.translation | example hypothesis: شما این آخر ##ه ##فته را می ##خ ##وا ##هی ##د?\n",
            "2023-06-09 11:07:12 | INFO | fairseq.tasks.translation | example reference: شما این هفت ##ه به ها ##وا ##یی می ##روی ##د, ها ##ن?\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  33% 9/27 [00:06<00:11,  1.51it/s]\u001b[A2023-06-09 11:07:13 | INFO | fairseq.tasks.translation | example hypothesis: \"آ ##ه زمانی که د ##قی ##قا در دست ##رس قرار می ##گیری ##د.\n",
            "2023-06-09 11:07:13 | INFO | fairseq.tasks.translation | example reference: او ##ه ##وم شما د ##قی ##قا چه زمانی در دست ##رس ه ##ستی ##د.\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  37% 10/27 [00:07<00:10,  1.60it/s]\u001b[A2023-06-09 11:07:13 | INFO | fairseq.tasks.translation | example hypothesis: من می ##خ ##وا ##هم بین دو و چهار نفر ش ##لو ##غ ه ##ست ##م,\n",
            "2023-06-09 11:07:13 | INFO | fairseq.tasks.translation | example reference: بین دو تا چهار و ن ##یم سر ##م ش ##لو ##غ است,\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  41% 11/27 [00:07<00:09,  1.70it/s]\u001b[A2023-06-09 11:07:14 | INFO | fairseq.tasks.translation | example hypothesis: \"\" \"\" \"\" \"\" \"\" \"\" \"\n",
            "2023-06-09 11:07:14 | INFO | fairseq.tasks.translation | example reference: خوب است, آ ##م بل ##ه, احتمال ##ا من گفت ##م,\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  44% 12/27 [00:08<00:08,  1.69it/s]\u001b[A2023-06-09 11:07:15 | INFO | fairseq.tasks.translation | example hypothesis: در چند هفت ##ه آ ##ینده, وقتی شما آزاد ه ##ستی ##د, وجود دارد?\n",
            "2023-06-09 11:07:15 | INFO | fairseq.tasks.translation | example reference: زمانی در دو هفت ##هی آ ##ینده وجود دارد که شما آزاد با ##شی?\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  48% 13/27 [00:08<00:08,  1.69it/s]\u001b[A2023-06-09 11:07:15 | INFO | fairseq.tasks.translation | example hypothesis: عالی است که برای من خ ##یلی خوب کار خ ##وا ##هم کرد,\n",
            "2023-06-09 11:07:15 | INFO | fairseq.tasks.translation | example reference: عالی. برای من بسیار خوب خواهد شد, شما را می ##بین ##م,\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  52% 14/27 [00:09<00:07,  1.69it/s]\u001b[A2023-06-09 11:07:16 | INFO | fairseq.tasks.translation | example hypothesis: اکنون ب ##د نیست, اما من ن ##می ##خ ##وا ##هم ر ##یس ##ک را ب ##گیر ##م.\n",
            "2023-06-09 11:07:16 | INFO | fairseq.tasks.translation | example reference: این همین ال ##ان ب ##د نیست ولی من ن ##می ##خ ##وا ##هم ر ##یس ##ک ک ##ن ##م.\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  56% 15/27 [00:10<00:07,  1.67it/s]\u001b[A2023-06-09 11:07:16 | INFO | fairseq.tasks.translation | example hypothesis: من می ##خ ##وا ##هم این کار را داشته با ##شم, اما دو ##شن ##به, دو ##شن ##به.\n",
            "2023-06-09 11:07:16 | INFO | fairseq.tasks.translation | example reference: تمام هفت ##ه - ی آ ##ینده ک ##نف ##ران ##سه ##ایی دار ##م, به غیر از روز دو ##شن ##به.\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  59% 16/27 [00:10<00:06,  1.66it/s]\u001b[A2023-06-09 11:07:17 | INFO | fairseq.tasks.translation | example hypothesis: اما, \"من میتوان ##م با شما مل ##اقات ک ##ن ##م, ص ##بح بیست و سوم.\n",
            "2023-06-09 11:07:17 | INFO | fairseq.tasks.translation | example reference: اما, آ ##ه من ص ##بح بیست و سوم, میتوان ##م با شما مل ##اقات ک ##ن ##م,\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  63% 17/27 [00:11<00:05,  1.73it/s]\u001b[A2023-06-09 11:07:18 | INFO | fairseq.tasks.translation | example hypothesis: با ##ش ##ه, \"آ ##ه ##و به ما اجازه ب ##دهی ##د تا این کار را انجام ده ##یم و این کار را انجام ده ##یم.\n",
            "2023-06-09 11:07:18 | INFO | fairseq.tasks.translation | example reference: خ ##ب, پس ب ##گذاری ##د آن را برای قبل از سی و یک ##م هم ##اه ##نگ ک ##نی ##م.\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  67% 18/27 [00:11<00:05,  1.73it/s]\u001b[A2023-06-09 11:07:18 | INFO | fairseq.tasks.translation | example hypothesis: اگر ##چه برخی امکان ##ات وجود دارد, \"احمد قبل از ن ##اه ##ار یا ن ##اه ##ار روز جمع ##ه?\n",
            "2023-06-09 11:07:18 | INFO | fairseq.tasks.translation | example reference: اگر ##چه احتمال دارد ام قبل از ن ##اه ##ار و یا حول و ##حو ##ش زمان ن ##اه ##ار روز جمع ##ه باشد?\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  70% 19/27 [00:12<00:04,  1.71it/s]\u001b[A2023-06-09 11:07:19 | INFO | fairseq.tasks.translation | example hypothesis: من در شهر ن ##خ ##وا ##هم بود. من باید به فی ##لا ##دل ##فی ##ا بر ##وم.\n",
            "2023-06-09 11:07:19 | INFO | fairseq.tasks.translation | example reference: من او ##ه ##وم هفت ##م, در شهر ن ##خ ##وا ##هم بود. من باید به فی ##لا ##دل ##فی ##ا بر ##وم.\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  74% 20/27 [00:13<00:04,  1.74it/s]\u001b[A2023-06-09 11:07:19 | INFO | fairseq.tasks.translation | example hypothesis: من در دفتر شما, در ساعت ش ##ان ##زدهم آوریل مل ##اقات خ ##وا ##هم کرد.\n",
            "2023-06-09 11:07:19 | INFO | fairseq.tasks.translation | example reference: من شما را در دفتر کار ##تان مل ##اقات خ ##وا ##هم کرد, روز جمع ##ه, ش ##ان ##زدهم آپ ##ری ##ل ساعت یک.\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  78% 21/27 [00:13<00:03,  1.56it/s]\u001b[A2023-06-09 11:07:20 | INFO | fairseq.tasks.translation | example hypothesis: بنابراین, چ ##را آن را انتخاب ن ##می ##کن ##ید. و \"من س ##عی می ##کن ##م آن را گ ##رس ##نه ک ##ن ##م.\"\n",
            "2023-06-09 11:07:20 | INFO | fairseq.tasks.translation | example reference: بنابراین, چ ##را شما یک زمانی را مشخص ن ##می ##کن ##ید. و من نیز برای گ ##رس ##نه شدن تلاش خ ##وا ##هم کرد.\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  81% 22/27 [00:14<00:03,  1.61it/s]\u001b[A2023-06-09 11:07:21 | INFO | fairseq.tasks.translation | example hypothesis: بنابراین بیست و ه ##شت ##م خوب است. \"\n",
            "2023-06-09 11:07:21 | INFO | fairseq.tasks.translation | example reference: پس. بیست و ه ##شت ##م خوب خواهد بود. میدان ##ید, او ##ه ##وم هر زمانی, در بعد ##از ##ظهر بیست و ه ##شت ##م.\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  85% 23/27 [00:14<00:02,  1.62it/s]\u001b[A2023-06-09 11:07:21 | INFO | fairseq.tasks.translation | example hypothesis: و من پس از ساعت یا ##زد ##ه, یا بعد از ساعت یا ##زد ##ه, \"احمد هر زمان سه\"\n",
            "2023-06-09 11:07:21 | INFO | fairseq.tasks.translation | example reference: و بعد از ساعت یا ##زد ##ه هم در دست ##رس خ ##وا ##هم بود, یا باز هم جمع ##ه بعدی هر زمانی قبل از سه,\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  89% 24/27 [00:15<00:01,  1.52it/s]\u001b[A2023-06-09 11:07:22 | INFO | fairseq.tasks.translation | example hypothesis: \"احمد, دو نفر برای من کامل ##ا عالی است, من ن ##می ##دان ##م\" احمد د ##قی ##قا چه مدت طول خواهد ک ##شید. \"\n",
            "2023-06-09 11:07:22 | INFO | fairseq.tasks.translation | example reference: او ##ه ##وم, دو برای من عالی است او ##ه ##وم, من به ##درس ##تی ن ##می ##دان ##م که آ ##ه, شما چه مدت زمانی دست ##رس خ ##وا ##هی ##د بود.\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  93% 25/27 [00:16<00:01,  1.46it/s]\u001b[A2023-06-09 11:07:23 | INFO | fairseq.tasks.translation | example hypothesis: و بعد سه - ش ##ن ##به از روز پنج ش ##ن ##به تا پنج ش ##ن ##به به این ##جا ن ##خ ##وا ##هم رفت, من تمام روز در س ##مین ##اری گ ##یر می ##کن ##م.\n",
            "2023-06-09 11:07:23 | INFO | fairseq.tasks.translation | example reference: و, آ ##ه و بعد از سه - ش ##ن ##به تا پنج ##شن ##به شما این ##جا ن ##خ ##وا ##هی ##د بود. جمع ##ه من تمام روز با س ##مین ##ار در ##گیر ه ##ست ##م,\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:  96% 26/27 [00:17<00:00,  1.40it/s]\u001b[A2023-06-09 11:07:24 | INFO | fairseq.tasks.translation | example hypothesis: \"من ن ##می ##تو ##ان ##م به نظر ن ##می ##رس ##د که کد ##ام یک از این کد ##ام به نظر ن ##می ##رس ##د که به این ترتیب ب ##تو ##ان ##م به\" احمد با شما ب ##پر ##دا ##زید \". وقتی این هفت ##ه برای شما خوب خواهد بود.\n",
            "2023-06-09 11:07:24 | INFO | fairseq.tasks.translation | example reference: آ ##ه به - نظر ن ##می ##رس ##د که من ب ##تو ##ان ##م کد ال ##کت ##ریکی را برای اجرا مه ##یا ک ##ن ##م, من نیاز دار ##م که آ ##ه با تو زمانی دوباره برای حدود بیش از دو ساعت, در این هفت ##ه مل ##اقات ک ##ن ##م. کی برای تو خوب است.\n",
            "\n",
            "epoch 004 | valid on 'valid' subset: 100% 27/27 [00:17<00:00,  1.41it/s]\u001b[A\n",
            "                                                                        \u001b[A2023-06-09 11:07:24 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 5.876 | nll_loss 2.894 | ppl 7.43 | bleu 42.06 | wps 3784.3 | wpb 2449.6 | bsz 148.1 | num_updates 25182 | best_bleu 43.09\n",
            "2023-06-09 11:07:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 25182 updates\n",
            "2023-06-09 11:07:24 | INFO | fairseq.trainer | Saving checkpoint to /content/data_bin/checkpoints1/checkpoint4.pt\n",
            "2023-06-09 11:07:28 | INFO | fairseq.trainer | Finished saving checkpoint to /content/data_bin/checkpoints1/checkpoint4.pt\n",
            "2023-06-09 11:07:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./data_bin/checkpoints1/checkpoint4.pt (epoch 4 @ 25182 updates, score 42.06) (writing took 6.549890309001057 seconds)\n",
            "2023-06-09 11:07:30 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
            "2023-06-09 11:07:30 | INFO | train | epoch 004 | loss 6.003 | nll_loss 3.052 | ppl 8.29 | wps 23256.5 | ups 6.12 | wpb 3802.7 | bsz 106.4 | num_updates 25182 | lr 0.000797104 | gnorm 0.254 | loss_scale 64 | train_wall 981 | gb_free 12.7 | wall 4132\n",
            "2023-06-09 11:07:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6296\n",
            "epoch 005:   0% 0/6296 [00:00<?, ?it/s]2023-06-09 11:07:30 | INFO | fairseq.trainer | begin training epoch 5\n",
            "2023-06-09 11:07:30 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 005:  41% 2572/6296 [06:52<09:55,  6.25it/s, loss=5.954, nll_loss=2.991, ppl=7.95, wps=23276.3, ups=6.17, wpb=3772.1, bsz=94.6, num_updates=27700, lr=0.000760011, gnorm=0.256, loss_scale=64, train_wall=16, gb_free=12.8, wall=4536]2023-06-09 11:14:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0\n",
            "epoch 005: 100% 6295/6296 [16:48<00:00,  7.52it/s, loss=5.946, nll_loss=2.985, ppl=7.92, wps=24144.6, ups=6.3, wpb=3831.5, bsz=103.3, num_updates=31400, lr=0.000713831, gnorm=0.25, loss_scale=32, train_wall=15, gb_free=12.7, wall=5129]2023-06-09 11:24:19 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:   0% 0/27 [00:00<?, ?it/s]\u001b[A2023-06-09 11:24:20 | INFO | fairseq.tasks.translation | example hypothesis: با توجه به اینکه\n",
            "2023-06-09 11:24:20 | INFO | fairseq.tasks.translation | example reference: خدا ##حافظ,\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:   4% 1/27 [00:00<00:25,  1.01it/s]\u001b[A2023-06-09 11:24:21 | INFO | fairseq.tasks.translation | example hypothesis: ح ##وم ##ه.\n",
            "2023-06-09 11:24:21 | INFO | fairseq.tasks.translation | example reference: هو ##م تن ##بل.\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:   7% 2/27 [00:01<00:21,  1.14it/s]\u001b[A2023-06-09 11:24:22 | INFO | fairseq.tasks.translation | example hypothesis: اما حال ##ا من این کار را انجام می ##دهم.\n",
            "2023-06-09 11:24:22 | INFO | fairseq.tasks.translation | example reference: اما ال ##ان انجام داده - ام.\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  11% 3/27 [00:02<00:20,  1.19it/s]\u001b[A2023-06-09 11:24:23 | INFO | fairseq.tasks.translation | example hypothesis: میتوان ##یم با مدتی هم مل ##اقات ک ##نی ##م?\n",
            "2023-06-09 11:24:23 | INFO | fairseq.tasks.translation | example reference: آیا میتوان ##یم زمانی مل ##اقات ک ##نی ##م?\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  15% 4/27 [00:03<00:18,  1.22it/s]\u001b[A2023-06-09 11:24:23 | INFO | fairseq.tasks.translation | example hypothesis: با ##ش ##ه, من آنجا خ ##وا ##هم بود.\n",
            "2023-06-09 11:24:23 | INFO | fairseq.tasks.translation | example reference: خوب ##ه, من آنجا خ ##وا ##هم بود.\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  19% 5/27 [00:03<00:15,  1.41it/s]\u001b[A2023-06-09 11:24:24 | INFO | fairseq.tasks.translation | example hypothesis: با ##ش ##ه, بیست و هفت ##م خوب است.\n",
            "2023-06-09 11:24:24 | INFO | fairseq.tasks.translation | example reference: با ##ش ##ه, بیست و هفت ##م خوب است.\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  22% 6/27 [00:04<00:13,  1.53it/s]\u001b[A2023-06-09 11:24:24 | INFO | fairseq.tasks.translation | example hypothesis: بیست و سوم? \"\n",
            "2023-06-09 11:24:24 | INFO | fairseq.tasks.translation | example reference: بیست و سوم? آ ##م خوب است,\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  26% 7/27 [00:04<00:12,  1.65it/s]\u001b[A2023-06-09 11:24:25 | INFO | fairseq.tasks.translation | example hypothesis: \"احمد چ ##طور در ##بار ##ه اول اکتبر.\"\n",
            "2023-06-09 11:24:25 | INFO | fairseq.tasks.translation | example reference: آ ##ه, اول اکتبر چه - طور است?\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  30% 8/27 [00:05<00:11,  1.67it/s]\u001b[A2023-06-09 11:24:25 | INFO | fairseq.tasks.translation | example hypothesis: آخر هفت ##ه ی آخر این هفت ##ه می ##خ ##وا ##هی ##د به ها ##وا ##یی بر ##وید?\n",
            "2023-06-09 11:24:25 | INFO | fairseq.tasks.translation | example reference: شما این هفت ##ه به ها ##وا ##یی می ##روی ##د, ها ##ن?\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  33% 9/27 [00:06<00:10,  1.72it/s]\u001b[A2023-06-09 11:24:26 | INFO | fairseq.tasks.translation | example hypothesis: \"آ ##م وقتی که د ##قی ##قا در دست ##رس قرار می ##گیری ##د.\n",
            "2023-06-09 11:24:26 | INFO | fairseq.tasks.translation | example reference: او ##ه ##وم شما د ##قی ##قا چه زمانی در دست ##رس ه ##ستی ##د.\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  37% 10/27 [00:06<00:09,  1.76it/s]\u001b[A2023-06-09 11:24:26 | INFO | fairseq.tasks.translation | example hypothesis: من می ##خ ##وا ##هم بین دو و چهار تا سی و یک ##م ش ##لو ##غ ه ##ست ##م,\n",
            "2023-06-09 11:24:26 | INFO | fairseq.tasks.translation | example reference: بین دو تا چهار و ن ##یم سر ##م ش ##لو ##غ است,\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  41% 11/27 [00:07<00:08,  1.83it/s]\u001b[A2023-06-09 11:24:27 | INFO | fairseq.tasks.translation | example hypothesis: احمد بل ##ه, مانند من گفت ##م: \"خ ##یلی عالی است.\n",
            "2023-06-09 11:24:27 | INFO | fairseq.tasks.translation | example reference: خوب است, آ ##م بل ##ه, احتمال ##ا من گفت ##م,\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  44% 12/27 [00:07<00:08,  1.80it/s]\u001b[A2023-06-09 11:24:28 | INFO | fairseq.tasks.translation | example hypothesis: در چند هفت ##ه آ ##ینده زمانی که شما آزاد ه ##ستی ##د, وجود دارد?\n",
            "2023-06-09 11:24:28 | INFO | fairseq.tasks.translation | example reference: زمانی در دو هفت ##هی آ ##ینده وجود دارد که شما آزاد با ##شی?\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  48% 13/27 [00:08<00:07,  1.78it/s]\u001b[A2023-06-09 11:24:28 | INFO | fairseq.tasks.translation | example hypothesis: عالی است که برای من خوب کار خ ##وا ##هم کرد, بعد ##ا شما را می ##بین ##م,\n",
            "2023-06-09 11:24:28 | INFO | fairseq.tasks.translation | example reference: عالی. برای من بسیار خوب خواهد شد, شما را می ##بین ##م,\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  52% 14/27 [00:08<00:07,  1.78it/s]\u001b[A2023-06-09 11:24:29 | INFO | fairseq.tasks.translation | example hypothesis: در حال حاضر ب ##د نیست اما من ن ##می ##خ ##وا ##هم ر ##یس ##ک ک ##ن ##م.\n",
            "2023-06-09 11:24:29 | INFO | fairseq.tasks.translation | example reference: این همین ال ##ان ب ##د نیست ولی من ن ##می ##خ ##وا ##هم ر ##یس ##ک ک ##ن ##م.\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  56% 15/27 [00:09<00:06,  1.76it/s]\u001b[A2023-06-09 11:24:29 | INFO | fairseq.tasks.translation | example hypothesis: من می ##خ ##وا ##هم این کار را داشته با ##شم, \"ک ##نف ##ران ##س های هفت ##ه آ ##ینده به ج ##ز دو ##شن ##به.\n",
            "2023-06-09 11:24:29 | INFO | fairseq.tasks.translation | example reference: تمام هفت ##ه - ی آ ##ینده ک ##نف ##ران ##سه ##ایی دار ##م, به غیر از روز دو ##شن ##به.\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  59% 16/27 [00:10<00:06,  1.72it/s]\u001b[A2023-06-09 11:24:30 | INFO | fairseq.tasks.translation | example hypothesis: اما, \"من میتوان ##م با شما مل ##اقات ک ##ن ##م, ص ##بح بیست و سوم,\n",
            "2023-06-09 11:24:30 | INFO | fairseq.tasks.translation | example reference: اما, آ ##ه من ص ##بح بیست و سوم, میتوان ##م با شما مل ##اقات ک ##ن ##م,\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  63% 17/27 [00:10<00:05,  1.77it/s]\u001b[A2023-06-09 11:24:30 | INFO | fairseq.tasks.translation | example hypothesis: با ##ش ##ه, \"ب ##گذاری ##د س ##عی ک ##نی ##م و این کار را قبل از سی و یک ##م انجام ده ##یم.\n",
            "2023-06-09 11:24:30 | INFO | fairseq.tasks.translation | example reference: خ ##ب, پس ب ##گذاری ##د آن را برای قبل از سی و یک ##م هم ##اه ##نگ ک ##نی ##م.\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  67% 18/27 [00:11<00:05,  1.74it/s]\u001b[A2023-06-09 11:24:31 | INFO | fairseq.tasks.translation | example hypothesis: اگر ##چه احتمال وجود دارد, \"احمد قبل از ن ##اه ##ار یا ن ##اه ##ار در روز جمع ##ه?\"\n",
            "2023-06-09 11:24:31 | INFO | fairseq.tasks.translation | example reference: اگر ##چه احتمال دارد ام قبل از ن ##اه ##ار و یا حول و ##حو ##ش زمان ن ##اه ##ار روز جمع ##ه باشد?\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  70% 19/27 [00:11<00:04,  1.71it/s]\u001b[A2023-06-09 11:24:32 | INFO | fairseq.tasks.translation | example hypothesis: من در شهر ن ##خ ##وا ##هم رفت. من باید به فی ##لا ##دل ##فی ##ا بر ##وم.\n",
            "2023-06-09 11:24:32 | INFO | fairseq.tasks.translation | example reference: من او ##ه ##وم هفت ##م, در شهر ن ##خ ##وا ##هم بود. من باید به فی ##لا ##دل ##فی ##ا بر ##وم.\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  74% 20/27 [00:12<00:04,  1.74it/s]\u001b[A2023-06-09 11:24:32 | INFO | fairseq.tasks.translation | example hypothesis: من در دفتر شما در ساعت یک ساعت ش ##ان ##زدهم آوریل مل ##اقات خ ##وا ##هم کرد.\n",
            "2023-06-09 11:24:32 | INFO | fairseq.tasks.translation | example reference: من شما را در دفتر کار ##تان مل ##اقات خ ##وا ##هم کرد, روز جمع ##ه, ش ##ان ##زدهم آپ ##ری ##ل ساعت یک.\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  78% 21/27 [00:12<00:03,  1.76it/s]\u001b[A2023-06-09 11:24:33 | INFO | fairseq.tasks.translation | example hypothesis: بنابراین, چ ##را زمان را انتخاب ن ##می ##کن ##ید. و \"من س ##عی خ ##وا ##هم کرد تا گ ##رس ##نگ ##ی ک ##ن ##م.\n",
            "2023-06-09 11:24:33 | INFO | fairseq.tasks.translation | example reference: بنابراین, چ ##را شما یک زمانی را مشخص ن ##می ##کن ##ید. و من نیز برای گ ##رس ##نه شدن تلاش خ ##وا ##هم کرد.\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  81% 22/27 [00:13<00:02,  1.72it/s]\u001b[A2023-06-09 11:24:34 | INFO | fairseq.tasks.translation | example hypothesis: به همین ترتیب بیست و ه ##شت ##م خوب است. \"\n",
            "2023-06-09 11:24:34 | INFO | fairseq.tasks.translation | example reference: پس. بیست و ه ##شت ##م خوب خواهد بود. میدان ##ید, او ##ه ##وم هر زمانی, در بعد ##از ##ظهر بیست و ه ##شت ##م.\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  85% 23/27 [00:14<00:02,  1.53it/s]\u001b[A2023-06-09 11:24:34 | INFO | fairseq.tasks.translation | example hypothesis: و من بعد از ساعت یا ##زد ##ه, و یا جمع ##ه آ ##ینده, در دست ##رس قرار خ ##وا ##هم گرفت,\n",
            "2023-06-09 11:24:34 | INFO | fairseq.tasks.translation | example reference: و بعد از ساعت یا ##زد ##ه هم در دست ##رس خ ##وا ##هم بود, یا باز هم جمع ##ه بعدی هر زمانی قبل از سه,\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  89% 24/27 [00:15<00:02,  1.41it/s]\u001b[A2023-06-09 11:24:35 | INFO | fairseq.tasks.translation | example hypothesis: \"احمد, دو نفر برای من کامل ##ا عالی است, من ن ##می ##دان ##م\" احمد د ##قی ##قا چه مدت طول خواهد ک ##شید. \"\n",
            "2023-06-09 11:24:35 | INFO | fairseq.tasks.translation | example reference: او ##ه ##وم, دو برای من عالی است او ##ه ##وم, من به ##درس ##تی ن ##می ##دان ##م که آ ##ه, شما چه مدت زمانی دست ##رس خ ##وا ##هی ##د بود.\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  93% 25/27 [00:15<00:01,  1.36it/s]\u001b[A2023-06-09 11:24:36 | INFO | fairseq.tasks.translation | example hypothesis: و \"آ ##ه و بعد از سه - ش ##ن ##به از روز پنج ش ##ن ##به تا روز پنج ش ##ن ##به به این ##جا ن ##خ ##وا ##هم رفت.\n",
            "2023-06-09 11:24:36 | INFO | fairseq.tasks.translation | example reference: و, آ ##ه و بعد از سه - ش ##ن ##به تا پنج ##شن ##به شما این ##جا ن ##خ ##وا ##هی ##د بود. جمع ##ه من تمام روز با س ##مین ##ار در ##گیر ه ##ست ##م,\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:  96% 26/27 [00:16<00:00,  1.33it/s]\u001b[A2023-06-09 11:24:37 | INFO | fairseq.tasks.translation | example hypothesis: \"من ن ##می ##تو ##ان ##م به نظر بر ##سد که کد ##ام یک از این قوانین را برای ت ##دو ##ین کردن به\" احمد با شما در حدود دو ساعت دیگر در این هفت ##ه بر ##آورد ##ه می ##کن ##م. زمانی که برای شما خوب است.\n",
            "2023-06-09 11:24:37 | INFO | fairseq.tasks.translation | example reference: آ ##ه به - نظر ن ##می ##رس ##د که من ب ##تو ##ان ##م کد ال ##کت ##ریکی را برای اجرا مه ##یا ک ##ن ##م, من نیاز دار ##م که آ ##ه با تو زمانی دوباره برای حدود بیش از دو ساعت, در این هفت ##ه مل ##اقات ک ##ن ##م. کی برای تو خوب است.\n",
            "\n",
            "epoch 005 | valid on 'valid' subset: 100% 27/27 [00:17<00:00,  1.33it/s]\u001b[A\n",
            "                                                                        \u001b[A2023-06-09 11:24:37 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 5.818 | nll_loss 2.811 | ppl 7.02 | bleu 44.99 | wps 3915 | wpb 2449.6 | bsz 148.1 | num_updates 31477 | best_bleu 44.99\n",
            "2023-06-09 11:24:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 31477 updates\n",
            "2023-06-09 11:24:37 | INFO | fairseq.trainer | Saving checkpoint to /content/data_bin/checkpoints1/checkpoint5.pt\n",
            "2023-06-09 11:24:39 | INFO | fairseq.trainer | Finished saving checkpoint to /content/data_bin/checkpoints1/checkpoint5.pt\n",
            "2023-06-09 11:24:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./data_bin/checkpoints1/checkpoint5.pt (epoch 5 @ 31477 updates, score 44.99) (writing took 7.455607571000655 seconds)\n",
            "2023-06-09 11:24:44 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n",
            "2023-06-09 11:24:44 | INFO | train | epoch 005 | loss 5.942 | nll_loss 2.977 | ppl 7.87 | wps 23151.9 | ups 6.09 | wpb 3802.9 | bsz 106.4 | num_updates 31477 | lr 0.000712957 | gnorm 0.255 | loss_scale 32 | train_wall 985 | gb_free 12.8 | wall 5166\n",
            "2023-06-09 11:24:44 | INFO | fairseq_cli.train | done training in 5165.9 seconds\n"
          ]
        }
      ],
      "source": [
        "!fairseq-train \\\n",
        "    \"./data_bin/\" \\\n",
        "    --arch lstm --share-all-embeddings --encoder-embed-path /content/embedding_weights.txt --decoder-embed-path /content/embedding_weights.txt  --encoder-embed-dim 768 --decoder-embed-dim 768 --decoder-out-embed-dim 768 \\\n",
        "    --encoder-layers 1\\\n",
        "    --decoder-layers 1\\\n",
        "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
        "    --lr 2e-3 --lr-scheduler inverse_sqrt --warmup-init-lr 0.0025 --warmup-updates 4000 \\\n",
        "    --dropout 0.25 --weight-decay 0.0001 \\\n",
        "    --criterion label_smoothed_cross_entropy --label-smoothing 0.2 \\\n",
        "    --max-tokens 4096 \\\n",
        "    --eval-bleu \\\n",
        "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
        "    --eval-bleu-detok moses \\\n",
        "    --eval-bleu-print-samples \\\n",
        "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
        "    --fp16 --memory-efficient-fp16 \\\n",
        "    --max-epoch 5 \\\n",
        "    --save-dir ./data_bin/checkpoints1/ \\\n",
        "    --tensorboard-logdir ./data_bin/logs1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate model using fairseq-generate"
      ],
      "metadata": {
        "id": "156NZ2neinEd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8e-EX91FW1T"
      },
      "outputs": [],
      "source": [
        "!fairseq-generate \\\n",
        "    \"./data_bin\" \\\n",
        "    --batch-size 128 \\\n",
        "    --path \"./data_bin/checkpoints1/checkpoint_best.pt\" \\\n",
        "    --beam 5 > \"./data_bin/new_eval1.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8SulN-aDFW53",
        "outputId": "ca7ef129-bc83-47da-8255-6993c8b1c53f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qA5ywMCFW_s"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir \"./data_bin/logs1\" --port=6009"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkzfV4Mul2Ft"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a5beb9c34ef47fcac17a99c58d01d2c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11413c3d73bd4f27a34afa84cfc31a94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ae15d09fbf5463a89ecf8b890e77182",
            "placeholder": "​",
            "style": "IPY_MODEL_d0c0773954274f43854a0a6101bcd6c6",
            "value": " 625/625 [00:00&lt;00:00, 18.3kB/s]"
          }
        },
        "1159f687662f4642abdd4a04985934f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11987db2c51641c98175af6c6357cc93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73d44e1179954f4593fdcc1b38b308e0",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6fc7bfcea1d400589b0ae763c7615a1",
            "value": 714290682
          }
        },
        "12e080efa2a14502b70ce9b99677d276": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8eb9643057a44918cfb6fa09732b9f2",
              "IPY_MODEL_a22c50f3e77f446fa49df97ea0144b31",
              "IPY_MODEL_f2bccc0ff42b4aa6a2dabb2e92c5feab"
            ],
            "layout": "IPY_MODEL_eee1f4f27e584adcbdbc68478f943bbc"
          }
        },
        "2d629ade586b450d808d1ead295e389b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30f936b6b3b0470eb4b555a63079bf86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "314d255f58a248848640465f1f97e9f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32f26cf5621545dbbec2c8b5b3005303": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a89840b12564e0888c3599ca7aa622a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ba9439780c74035bae481e7d9333747": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f442584f0914d7eb76b294fb7ca4e06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4db296b293fb4ba68e0b83f1f64a2150": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54e7cc54a127470587fd4b6250ddd8b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ae15d09fbf5463a89ecf8b890e77182": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c94ab2d539d4e59952b788bef16a285": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_924a5ea11f0a4a7b82e5a3cf7e526a18",
              "IPY_MODEL_11987db2c51641c98175af6c6357cc93",
              "IPY_MODEL_8e25f496011144319a35e64992d06c0c"
            ],
            "layout": "IPY_MODEL_30f936b6b3b0470eb4b555a63079bf86"
          }
        },
        "5e6cfeefcd074cb78eb12f50860da187": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab6f293a6f8648838b1bd5aef413c0b5",
              "IPY_MODEL_dbb589f1d9764471a59b32b84df977c0",
              "IPY_MODEL_7dd40ab4b5da43dbba2a8718ecb1d3c9"
            ],
            "layout": "IPY_MODEL_dc3715d6dd474193b989136d9427daee"
          }
        },
        "664f15bee36242b6b2cef12960d51c8e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73d44e1179954f4593fdcc1b38b308e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7742ae4354374b729621ea4c3cb842a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dd40ab4b5da43dbba2a8718ecb1d3c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a5beb9c34ef47fcac17a99c58d01d2c",
            "placeholder": "​",
            "style": "IPY_MODEL_8cb7acee2a144897bf1f917b9bdc37d5",
            "value": " 29.0/29.0 [00:00&lt;00:00, 596B/s]"
          }
        },
        "7e330f9a13144146ad636e54b6599d71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a340d3fe222a4f4ca217da49e6d8c8c1",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_314d255f58a248848640465f1f97e9f8",
            "value": 625
          }
        },
        "888f4b42fcb84363807caf83bfeb48b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cb7acee2a144897bf1f917b9bdc37d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e25f496011144319a35e64992d06c0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4c17a172d9e4b2d9b59b5f17be000a2",
            "placeholder": "​",
            "style": "IPY_MODEL_2d629ade586b450d808d1ead295e389b",
            "value": " 714M/714M [00:03&lt;00:00, 224MB/s]"
          }
        },
        "924a5ea11f0a4a7b82e5a3cf7e526a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_664f15bee36242b6b2cef12960d51c8e",
            "placeholder": "​",
            "style": "IPY_MODEL_888f4b42fcb84363807caf83bfeb48b5",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "9611c81761f24592865318a61b61d9b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9afa4ae96ab545198a216c9cd6ac69e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9e979ea530641e99656fbdd71b481de",
              "IPY_MODEL_7e330f9a13144146ad636e54b6599d71",
              "IPY_MODEL_11413c3d73bd4f27a34afa84cfc31a94"
            ],
            "layout": "IPY_MODEL_ec523e0fb2524c529f1c3c5c319a1b25"
          }
        },
        "a22c50f3e77f446fa49df97ea0144b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9611c81761f24592865318a61b61d9b3",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4db296b293fb4ba68e0b83f1f64a2150",
            "value": 995526
          }
        },
        "a340d3fe222a4f4ca217da49e6d8c8c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4c17a172d9e4b2d9b59b5f17be000a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6127714925f427b9d77b38b267edfa0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a84f9530a557458a80f70bba12810400": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab6f293a6f8648838b1bd5aef413c0b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54e7cc54a127470587fd4b6250ddd8b1",
            "placeholder": "​",
            "style": "IPY_MODEL_3f442584f0914d7eb76b294fb7ca4e06",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "b6fc7bfcea1d400589b0ae763c7615a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb0120a618814ee29f03a5050d6abe11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0c0773954274f43854a0a6101bcd6c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbb589f1d9764471a59b32b84df977c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1159f687662f4642abdd4a04985934f7",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a84f9530a557458a80f70bba12810400",
            "value": 29
          }
        },
        "dc3715d6dd474193b989136d9427daee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8eb9643057a44918cfb6fa09732b9f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a89840b12564e0888c3599ca7aa622a",
            "placeholder": "​",
            "style": "IPY_MODEL_7742ae4354374b729621ea4c3cb842a9",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "e9e979ea530641e99656fbdd71b481de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6127714925f427b9d77b38b267edfa0",
            "placeholder": "​",
            "style": "IPY_MODEL_3ba9439780c74035bae481e7d9333747",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "ec523e0fb2524c529f1c3c5c319a1b25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eee1f4f27e584adcbdbc68478f943bbc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2bccc0ff42b4aa6a2dabb2e92c5feab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32f26cf5621545dbbec2c8b5b3005303",
            "placeholder": "​",
            "style": "IPY_MODEL_cb0120a618814ee29f03a5050d6abe11",
            "value": " 996k/996k [00:00&lt;00:00, 14.4MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}